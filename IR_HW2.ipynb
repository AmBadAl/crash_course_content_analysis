{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2ca4e5a",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    تحلیل محتوای متنی ویدیوهای آموزشی شاخه‌های علوم انسانی و علوم کامپیوتر Crash Course\n",
    "</div>\n",
    "</h1>\n",
    "\n",
    "\n",
    "<h2>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'> امیررضا باقری دلویی - 98109804 \n",
    "    </div>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3377d83e",
   "metadata": {
    "id": "3377d83e"
   },
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Llmmu6YoA8dJ",
   "metadata": {
    "id": "Llmmu6YoA8dJ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from pandas) (1.21.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\python38\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\python38\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python38\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (1.21.0)\n",
      "Requirement already satisfied: bs4 in c:\\python38\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python38\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python38\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Requirement already satisfied: requests in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests) (2.0.10)\n",
      "Requirement already satisfied: spacy in c:\\python38\\lib\\site-packages (3.2.4)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (8.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (1.21.0)\n",
      "Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from spacy) (47.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python38\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python38\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\python38\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\python38\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\python38\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python38\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python38\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python38\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\python38\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\python38\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\python38\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\python38\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\python38\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\python38\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\python38\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from click<8.1.0->spacy) (0.3.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->spacy) (2.0.1)\n",
      "Requirement already satisfied: youtube_transcript_api in c:\\python38\\lib\\site-packages (0.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from youtube_transcript_api) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests->youtube_transcript_api) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests->youtube_transcript_api) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests->youtube_transcript_api) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests->youtube_transcript_api) (2021.10.8)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (2.46.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-api-python-client) (2.7.2)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-api-python-client) (0.20.4)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-api-python-client) (2.6.6)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\python38\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.56.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python38\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\python38\\lib\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (5.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\python38\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install spacy\n",
    "!pip install youtube_transcript_api\n",
    "!pip install google-api-python-client --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064e8eb",
   "metadata": {
    "id": "1064e8eb"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Jx5-XQ_-AfXT",
   "metadata": {
    "id": "Jx5-XQ_-AfXT"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "yrwIej-yAqKv",
   "metadata": {
    "id": "yrwIej-yAqKv"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib\n",
    "\n",
    "import googleapiclient.discovery\n",
    "from urllib.parse import parse_qs, urlparse\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi as yta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knMLL3HxjNrL",
   "metadata": {
    "id": "knMLL3HxjNrL"
   },
   "source": [
    "# Setup Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "oysD5lUNlO1R",
   "metadata": {
    "id": "oysD5lUNlO1R"
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "_QcPOMaXjQab",
   "metadata": {
    "id": "_QcPOMaXjQab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "     -------------------------------------- 13.9/13.9 MB 272.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\python38\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (47.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\python38\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.1)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from click<8.1.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.3.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\python38\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python38\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "TrLuXD_XjSmQ",
   "metadata": {
    "id": "TrLuXD_XjSmQ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "/ Loading compatibility table...\n",
      "- Loading compatibility table...\n",
      "\\ Loading compatibility table...\n",
      "| Loading compatibility table...\n",
      "\u001b[2K[+] Loaded compatibility table\n",
      "\u001b[1m\n",
      "================= Installed pipeline packages (spaCy v3.2.4) =================\u001b[0m\n",
      "[i] spaCy installation: c:\\python38\\lib\\site-packages\\spacy\n",
      "\n",
      "NAME              SPACY            VERSION      \n",
      "en_core_web_lg    >=3.2.0,<3.3.0   3.2.0     [+]\n",
      "en_core_web_sm    >=3.2.0,<3.3.0   3.2.0     [+]\n",
      "en_core_web_trf   >=3.2.0,<3.3.0   3.2.0     [+]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m spacy validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8Dv3HNbejU22",
   "metadata": {
    "id": "8Dv3HNbejU22"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6AOXuIJ4iitc",
   "metadata": {
    "id": "6AOXuIJ4iitc"
   },
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۱. اطلاعات کلی راجع به داده\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11424012",
   "metadata": {},
   "source": [
    "<div style='direction:rtl; font-family: \"B Nazanin\"; font-size: 18px;'> \n",
    "کانال یوتیوب Crash Course، یک کانال آموزشی است که در آن دوره‌های آموزشی برای علوم مختلف ارائه می‌شود. اکثر این دوره‌ها مقدماتی هستند و مفاهیم پایه علوم در آن توضیح داده می‌شود. \n",
    "برای جمع آوری داده، سراغ چند دوره گزینشی مرتبط با علوم انسانی و علوم کامپبوتر از این کانال رفتیم. این دوره‌ها به ترتیب عبارتند از World History و Economics و Computer Science و Philosophy و Sociology و Psychology. \n",
    "\n",
    "<div style=\"direction:rtl\"> \n",
    "در این پروژه، زیرنویس مربوط به ویدیو‌های این دوره‌ها دانلود شده و پس از تمیز کردن و دسته بندی آنها، کارهای پیش پردازشی روی آن انجام شده و نهایتا کلمات پر تکرار و کلمات کلیدی آن استخراج شود. هدف این است که متوجه شویم که مفاهیم پایه این شاخه‌های علوم انسانی و علوم کامپبوتر، عمدتا شامل چه کلماتی هستند. این کار می‌تواند برای مفاهیم پایه هر زیرشاخه این علوم نیز به کار برود و در نتیجه بتوان به طرز بهینه‌ای جملات علمی یا مقالات را دسته‌بندی کرد."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01cdef3",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۲. جمع آوری داده\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5895ed",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    اجرای این بخش نیاز به اتصال به فیلترشکن دارد و در صورت وجود فایل‌ها لازم نیست اجرا شود\n",
    "    </div>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678b0cb",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "ابتدا لینک مربوط به playlist هر دوره در دیکشنری playlist_links ذخیره شد. سپس با استفاده از تابع get_playlist_links، لینک‌های موجود در هر playlist و اطلاعات دیگر از جمله عنوان ویدیو و تاریخ انتشار آن، بدست آمد و در دیکشنری videos_info ذخیره شد. درخواست دریافت این لینک‌ها با استفاده از api گوگل و سپس گرفتن API Key مخصوص به پروژه از طریق سرویس Google Developers انجام شد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BHTmp-QRGZ_l",
   "metadata": {
    "id": "BHTmp-QRGZ_l"
   },
   "outputs": [],
   "source": [
    "def get_playlist_links(playlist_url):\n",
    "    query = parse_qs(urlparse(playlist_url).query, keep_blank_values=True)\n",
    "    playlist_id = query[\"list\"][0]\n",
    "\n",
    "    print(f'get all playlist items links from {playlist_id}')\n",
    "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey = \"AIzaSyA5W7kWR7YnyjW5dLTle3l7I2iQ8VJdHvI\")\n",
    "\n",
    "    request = youtube.playlistItems().list(\n",
    "        part = \"snippet\",\n",
    "        playlistId = playlist_id,\n",
    "        maxResults = 50\n",
    "    )\n",
    "    response = request.execute()\n",
    "\n",
    "    playlist_items = []\n",
    "    while request is not None:\n",
    "        response = request.execute()\n",
    "        playlist_items += response[\"items\"]\n",
    "        request = youtube.playlistItems().list_next(request, response)\n",
    "\n",
    "    print(f\"total: {len(playlist_items)}\")\n",
    "    return([ \n",
    "        {\"url\": f'https://www.youtube.com/watch?v={t[\"snippet\"][\"resourceId\"][\"videoId\"]}&list={playlist_id}&t=0s',\n",
    "         \"title\": t[\"snippet\"][\"title\"],\n",
    "         \"published at\": t[\"snippet\"][\"publishedAt\"]}\n",
    "        for t in playlist_items\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "CpjlfW7MIcZ9",
   "metadata": {
    "id": "CpjlfW7MIcZ9"
   },
   "outputs": [],
   "source": [
    "def retrieve_text_srt(srt):\n",
    "    pure_text = ''\n",
    "    for i in srt:\n",
    "        text = ast.literal_eval(str(i).replace('\\\\n', ' '))['text']\n",
    "        pure_text += (text+' ')\n",
    "    return pure_text\n",
    "\n",
    "def write_transcript(subject, info, file_name):\n",
    "    url, title, published_at = info[\"url\"], info[\"title\"], info[\"published at\"].split(\"T\")[0]\n",
    "    srt = yta.get_transcript(url.split('https://www.youtube.com/watch?v=')[1])\n",
    "    pure_text = retrieve_text_srt(srt)\n",
    "    \n",
    "    with open(subject + '/' + file_name + '.json', 'w') as f:\n",
    "        json_info = {\"Subject\": subject,\n",
    "                \"Title\": title,\n",
    "                \"Text\": pure_text,\n",
    "                \"Publish Time\": published_at,\n",
    "                \"URL\": url\n",
    "                }\n",
    "        f.write(json.dumps(json_info, indent=4, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "N1hJ7buWLf7V",
   "metadata": {
    "id": "N1hJ7buWLf7V"
   },
   "outputs": [],
   "source": [
    "playlist_links = {'World History': 'https://www.youtube.com/playlist?list=PLBDA2E52FB1EF80C9',\n",
    "                  'Economics': 'https://www.youtube.com/playlist?list=PL8dPuuaLjXtPNZwz5_o_5uirJ8gQXnhEO',\n",
    "                  'Computer Science': 'https://www.youtube.com/playlist?list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo',\n",
    "                  'Philosophy': 'https://www.youtube.com/playlist?list=PL8dPuuaLjXtNgK6MZucdYldNkMybYIHKR',\n",
    "                  'Sociology': 'https://www.youtube.com/playlist?list=PL8dPuuaLjXtMJ-AfB_7J1538YKWkZAnGA',\n",
    "                  'Psychology': 'https://www.youtube.com/playlist?list=PL8dPuuaLjXtOPRKzVLY0jJY-uHOH9KVU6'\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bJplnNw0MVek",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJplnNw0MVek",
    "outputId": "9fb162b4-ab86-4d30-a0e1-55a1151b426a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get all playlist items links from PLBDA2E52FB1EF80C9\n",
      "total: 42\n",
      "get all playlist items links from PL8dPuuaLjXtPNZwz5_o_5uirJ8gQXnhEO\n",
      "total: 36\n",
      "get all playlist items links from PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo\n",
      "total: 41\n",
      "get all playlist items links from PL8dPuuaLjXtNgK6MZucdYldNkMybYIHKR\n",
      "total: 47\n",
      "get all playlist items links from PL8dPuuaLjXtMJ-AfB_7J1538YKWkZAnGA\n",
      "total: 45\n",
      "get all playlist items links from PL8dPuuaLjXtOPRKzVLY0jJY-uHOH9KVU6\n",
      "total: 41\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"World History\", \"Economics\", \"Computer Science\", \"Philosophy\", \"Sociology\", \"Psychology\"]\n",
    "\n",
    "videos_info = dict()\n",
    "for subject in subjects:\n",
    "    videos_info[subject] = get_playlist_links(playlist_links[subject])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da243c6c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "پس از آن، فولدرهای مخصوص به هر موضوع ساخته شد. اکنون که لینک ویدیوهای هر موضوع را در اختیار داریم، با استفاده از تابع write_transcript، محتوای هر ویدیو شامل موضوع، عنوان، متن، زمان انتشار، و URL آن را در فایل‌های json، داخل فولدر مربوط به آن موضوع ذخیره می‌کنیم. فایل زیرنویس با استفاده از تابع get_transcript کتابخانه YouTubeTranscriptApi دریافت می‌شود و سپس با استفاده از تابع retrieve_text_srt محتوای متنی آن تمیز می‌شود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Y8OKd5uA-kS4",
   "metadata": {
    "id": "Y8OKd5uA-kS4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    os.makedirs(subject, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b0aa852",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    for i, info in enumerate(videos_info[subject]):\n",
    "        write_transcript(subject, info, str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdfaaa4",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۳. استخراج داده ساختارمند از فایل\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dc513a",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "پس از آنکه داده‌ها در فایل‌های json ذخیره شدند، آنها را با استفاده از تابع get_data از فایل خوانده و همگی را در لیست all_data تجمیع می‌کنیم. نهایتا با pd.json_normalize آن را به صورت یک DataFrame ساختارمند تبدیل می‌کنیم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ZHcxf-MSqHa1",
   "metadata": {
    "id": "ZHcxf-MSqHa1"
   },
   "outputs": [],
   "source": [
    "def get_data(directory):\n",
    "    data = []\n",
    "    for filename in os.listdir(directory):\n",
    "        file_dir = os.path.join(directory, filename)\n",
    "        if (os.path.isfile(file_dir)):\n",
    "            with open(file_dir, 'r') as f:\n",
    "                data.append(json.load(f))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sMTjA_3vrFEm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMTjA_3vrFEm",
    "outputId": "5ec64ee0-f390-4935-960e-5e9a2348937e"
   },
   "outputs": [],
   "source": [
    "subjects = [\"World History\", \"Economics\", \"Computer Science\", \"Philosophy\", \"Sociology\", \"Psychology\"]\n",
    "all_data = []\n",
    "for subject in subjects:\n",
    "    all_data += get_data(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dtJO5h0d5yGD",
   "metadata": {
    "id": "dtJO5h0d5yGD",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Publish Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World History</td>\n",
       "      <td>The Agricultural Revolution: Crash Course Worl...</td>\n",
       "      <td>Hello, learned and astonishingly attractive pu...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=Yocja_N5s1I&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World History</td>\n",
       "      <td>Indus Valley Civilization: Crash Course World ...</td>\n",
       "      <td>Hi, I’m John Green, and this is Crash Course W...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=n7ndRwqJYDM&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World History</td>\n",
       "      <td>Christianity from Judaism to Constantine: Cras...</td>\n",
       "      <td>Hi there my name’s John Green; this is Crash C...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TG55ErfdaeY&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World History</td>\n",
       "      <td>Fall of The Roman Empire...in the 15th Century...</td>\n",
       "      <td>Hi there, my name’s John Green; this is Crash ...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=3PszVWZNWVA&amp;li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World History</td>\n",
       "      <td>Islam, the Quran, and the Five Pillars: Crash ...</td>\n",
       "      <td>Hi there, I’m John Green, this is Crash Course...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TpcbfxtdoI8&amp;li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject                                              Title  \\\n",
       "0  World History  The Agricultural Revolution: Crash Course Worl...   \n",
       "1  World History  Indus Valley Civilization: Crash Course World ...   \n",
       "2  World History  Christianity from Judaism to Constantine: Cras...   \n",
       "3  World History  Fall of The Roman Empire...in the 15th Century...   \n",
       "4  World History  Islam, the Quran, and the Five Pillars: Crash ...   \n",
       "\n",
       "                                                Text Publish Time  \\\n",
       "0  Hello, learned and astonishingly attractive pu...   2012-01-26   \n",
       "1  Hi, I’m John Green, and this is Crash Course W...   2012-01-26   \n",
       "2  Hi there my name’s John Green; this is Crash C...   2012-01-26   \n",
       "3  Hi there, my name’s John Green; this is Crash ...   2012-01-26   \n",
       "4  Hi there, I’m John Green, this is Crash Course...   2012-01-26   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.youtube.com/watch?v=Yocja_N5s1I&li...  \n",
       "1  https://www.youtube.com/watch?v=n7ndRwqJYDM&li...  \n",
       "2  https://www.youtube.com/watch?v=TG55ErfdaeY&li...  \n",
       "3  https://www.youtube.com/watch?v=3PszVWZNWVA&li...  \n",
       "4  https://www.youtube.com/watch?v=TpcbfxtdoI8&li...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.json_normalize(all_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc19ecd",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    نمونه\n",
    "    </div>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37fdfdc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Computer Science</td>\n",
       "      <td>The Central Processing Unit (CPU): Crash Cours...</td>\n",
       "      <td>Hi, I’m Carrie Anne, this is Crash Course Comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Economics</td>\n",
       "      <td>The Economics of Happiness: Crash Course Econ #35</td>\n",
       "      <td>Hi, I’m Adriene Hill, and this is Crash Course...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>Contractarianism: Crash Course Philosophy #37</td>\n",
       "      <td>Imagine a world without rules. Nothing is ille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Psychology</td>\n",
       "      <td>Cognition - How Your Mind Can Amaze and Betray...</td>\n",
       "      <td>Why do smart people make dumb decisions? Why d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Sociology</td>\n",
       "      <td>Religion: Crash Course Sociology #39</td>\n",
       "      <td>Religion might not seem like something a socio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>World History</td>\n",
       "      <td>Samurai, Daimyo, Matthew Perry, and Nationalis...</td>\n",
       "      <td>Hi, I'm John Green. This is Crash Course World...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Subject                                              Title  \\\n",
       "116  Computer Science  The Central Processing Unit (CPU): Crash Cours...   \n",
       "71          Economics  The Economics of Happiness: Crash Course Econ #35   \n",
       "150        Philosophy      Contractarianism: Crash Course Philosophy #37   \n",
       "218        Psychology  Cognition - How Your Mind Can Amaze and Betray...   \n",
       "199         Sociology               Religion: Crash Course Sociology #39   \n",
       "27      World History  Samurai, Daimyo, Matthew Perry, and Nationalis...   \n",
       "\n",
       "                                                  Text  \n",
       "116  Hi, I’m Carrie Anne, this is Crash Course Comp...  \n",
       "71   Hi, I’m Adriene Hill, and this is Crash Course...  \n",
       "150  Imagine a world without rules. Nothing is ille...  \n",
       "218  Why do smart people make dumb decisions? Why d...  \n",
       "199  Religion might not seem like something a socio...  \n",
       "27   Hi, I'm John Green. This is Crash Course World...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = df.groupby(\"Subject\").sample(n=1)[[\"Subject\", \"Title\", \"Text\"]]\n",
    "\n",
    "pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e16f5",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۴. استخراج جملات\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff86ad11",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "در این بخش، داده‌های متنی مربوط به هر موضوع تجمیع شد. سپس با استفاده از تابع get_sentences، مدل nlp که ابتدا تعریف کرده بودیم روی آن اعمال و لیست جملات آن در دیکشنری all_sentences ذخیره شد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b524c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(sentences_list):\n",
    "    sentences_string = ''.join(map(str, sentences_list))\n",
    "    doc = nlp(sentences_string)\n",
    "    return list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34c3f7a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "all_sentences = dict()\n",
    "\n",
    "subject_sents = df.groupby(\"Subject\")['Text'].apply(list)\n",
    "subject_sents = pd.DataFrame(subject_sents)\n",
    "for subject in subjects:\n",
    "    all_sentences[subject] = get_sentences(list(chain.from_iterable(subject_sents.loc[subject]['Text'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a37127",
   "metadata": {},
   "source": [
    "<h2>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    نمونه\n",
    "    </div>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53317d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This panel was full of little sockets, into which a programmer would plug cables to pass values and signals between different parts of the machine.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>Xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>panel</td>\n",
       "      <td>panel</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>was</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>full</td>\n",
       "      <td>full</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sockets</td>\n",
       "      <td>socket</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>into</td>\n",
       "      <td>into</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>which</td>\n",
       "      <td>which</td>\n",
       "      <td>PRON</td>\n",
       "      <td>pronoun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>programmer</td>\n",
       "      <td>programmer</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "      <td>AUX</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>plug</td>\n",
       "      <td>plug</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cables</td>\n",
       "      <td>cable</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>PART</td>\n",
       "      <td>particle</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pass</td>\n",
       "      <td>pass</td>\n",
       "      <td>VERB</td>\n",
       "      <td>verb</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>values</td>\n",
       "      <td>value</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>coordinating conjunction</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>signals</td>\n",
       "      <td>signal</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>between</td>\n",
       "      <td>between</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>different</td>\n",
       "      <td>different</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>adjective</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>parts</td>\n",
       "      <td>part</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>adposition</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>determiner</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>machine</td>\n",
       "      <td>machine</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Text       Lemma    POS                   Meaning Shape\n",
       "0         This        this    DET                determiner  Xxxx\n",
       "1        panel       panel   NOUN                      noun  xxxx\n",
       "2          was          be    AUX                 auxiliary   xxx\n",
       "3         full        full    ADJ                 adjective  xxxx\n",
       "4           of          of    ADP                adposition    xx\n",
       "5       little      little    ADJ                 adjective  xxxx\n",
       "6      sockets      socket   NOUN                      noun  xxxx\n",
       "7            ,           ,  PUNCT               punctuation     ,\n",
       "8         into        into    ADP                adposition  xxxx\n",
       "9        which       which   PRON                   pronoun  xxxx\n",
       "10           a           a    DET                determiner     x\n",
       "11  programmer  programmer   NOUN                      noun  xxxx\n",
       "12       would       would    AUX                 auxiliary  xxxx\n",
       "13        plug        plug   VERB                      verb  xxxx\n",
       "14      cables       cable   NOUN                      noun  xxxx\n",
       "15          to          to   PART                  particle    xx\n",
       "16        pass        pass   VERB                      verb  xxxx\n",
       "17      values       value   NOUN                      noun  xxxx\n",
       "18         and         and  CCONJ  coordinating conjunction   xxx\n",
       "19     signals      signal   NOUN                      noun  xxxx\n",
       "20     between     between    ADP                adposition  xxxx\n",
       "21   different   different    ADJ                 adjective  xxxx\n",
       "22       parts        part   NOUN                      noun  xxxx\n",
       "23          of          of    ADP                adposition    xx\n",
       "24         the         the    DET                determiner   xxx\n",
       "25     machine     machine   NOUN                      noun  xxxx\n",
       "26           .           .  PUNCT               punctuation     ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = random.randint(0, len(subjects) - 1)\n",
    "x = str(random.sample(all_sentences[subjects[i]], k=1)[0])\n",
    "print(x)\n",
    "display(pd.DataFrame([[t.text, t.lemma_, t.pos_, spacy.explain(t.pos_), t.shape_] for t in nlp(x)],\n",
    "            columns=['Text', 'Lemma', 'POS', 'Meaning','Shape']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2288a5",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۵. مشخصات کلی متن\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0111d69",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "در بخش مشخصات کلی متن، برای هر موضوع اطلاعاتی شامل تعداد جملات، تعداد کل توکن‌ها، تعداد توکن‌های یکتا، میانگین طول جملات، میانگین طول هر توکن، و طولانی‌ترین توکن، در دیکشنری general_info ذخیره و نهایتا با تبدیل به DataFrame، نمایش داده شد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6098dc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_general_info(sents):\n",
    "    num_sents = len(sents)\n",
    "    tokens = list(chain.from_iterable([[str(token) for token in sent] for sent in sents]))\n",
    "    num_tokens = len(tokens)\n",
    "    num_unique_tokens = len(set(tokens))\n",
    "    avg_sent_len = num_tokens/num_sents\n",
    "    avg_token_len = sum([len(token) for token in tokens])/num_tokens\n",
    "    longest_token = tokens[np.argmax([len(token) for token in tokens])]\n",
    "    \n",
    "    return {\"Number of Sentences\": num_sents,\n",
    "            \"Number of Tokens\": num_tokens,\n",
    "            \"Number of Unique Tokens\": num_unique_tokens,\n",
    "            \"Average Sentence Length\": avg_sent_len,\n",
    "            \"Average Token Length\": avg_token_len,\n",
    "            \"Longest Token\": longest_token\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9be473dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_info = dict()\n",
    "for subject in subjects:\n",
    "    general_info[subject] = get_general_info(all_sentences[subject])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5c2bf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Sentences</th>\n",
       "      <th>Number of Tokens</th>\n",
       "      <th>Number of Unique Tokens</th>\n",
       "      <th>Average Sentence Length</th>\n",
       "      <th>Average Token Length</th>\n",
       "      <th>Longest Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>World History</th>\n",
       "      <td>5752</td>\n",
       "      <td>117550</td>\n",
       "      <td>11343</td>\n",
       "      <td>20.43637</td>\n",
       "      <td>4.112607</td>\n",
       "      <td>counterrevolutionaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>4687</td>\n",
       "      <td>81371</td>\n",
       "      <td>6899</td>\n",
       "      <td>17.360999</td>\n",
       "      <td>4.196667</td>\n",
       "      <td>patreon.com/crashcourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Science</th>\n",
       "      <td>5011</td>\n",
       "      <td>104214</td>\n",
       "      <td>8565</td>\n",
       "      <td>20.797046</td>\n",
       "      <td>4.099229</td>\n",
       "      <td>curiositystream.com/crashcourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philosophy</th>\n",
       "      <td>5528</td>\n",
       "      <td>106601</td>\n",
       "      <td>7290</td>\n",
       "      <td>19.283828</td>\n",
       "      <td>3.988274</td>\n",
       "      <td>squarespace.com/crashcourse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sociology</th>\n",
       "      <td>4811</td>\n",
       "      <td>104701</td>\n",
       "      <td>7701</td>\n",
       "      <td>21.762835</td>\n",
       "      <td>4.33716</td>\n",
       "      <td>Overcriminalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psychology</th>\n",
       "      <td>3966</td>\n",
       "      <td>96051</td>\n",
       "      <td>9392</td>\n",
       "      <td>24.218608</td>\n",
       "      <td>4.311616</td>\n",
       "      <td>Subbable.com/CrashCourse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Number of Sentences Number of Tokens Number of Unique Tokens  \\\n",
       "World History                   5752           117550                   11343   \n",
       "Economics                       4687            81371                    6899   \n",
       "Computer Science                5011           104214                    8565   \n",
       "Philosophy                      5528           106601                    7290   \n",
       "Sociology                       4811           104701                    7701   \n",
       "Psychology                      3966            96051                    9392   \n",
       "\n",
       "                 Average Sentence Length Average Token Length  \\\n",
       "World History                   20.43637             4.112607   \n",
       "Economics                      17.360999             4.196667   \n",
       "Computer Science               20.797046             4.099229   \n",
       "Philosophy                     19.283828             3.988274   \n",
       "Sociology                      21.762835              4.33716   \n",
       "Psychology                     24.218608             4.311616   \n",
       "\n",
       "                                    Longest Token  \n",
       "World History              counterrevolutionaries  \n",
       "Economics                 patreon.com/crashcourse  \n",
       "Computer Science  curiositystream.com/crashcourse  \n",
       "Philosophy            squarespace.com/crashcourse  \n",
       "Sociology                     Overcriminalization  \n",
       "Psychology               Subbable.com/CrashCourse  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "info = pd.DataFrame(general_info).T\n",
    "display(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e224a",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۶. نرمالیزه کردن\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f8a99",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "ابتدا ستونی به نام Doc Text، با اعمال مدل nlp روی ستون Text اضافه شد. سپس ستون Normalized Words با اعمال تابع normalize_sentence روی ستون Doc Text، بدست آمد.\n",
    "در تابع normalize_sentence، با توجه به شروط stopword_removal، punctuation_removal، lower_case، lemmatize و minimum_length، تغییرات روی جمله توکنایز شده توسط مدل nlp اعمال می‌شود."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c3dae49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Publish Time</th>\n",
       "      <th>URL</th>\n",
       "      <th>Doc Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World History</td>\n",
       "      <td>The Agricultural Revolution: Crash Course Worl...</td>\n",
       "      <td>Hello, learned and astonishingly attractive pu...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=Yocja_N5s1I&amp;li...</td>\n",
       "      <td>(Hello, ,, learned, and, astonishingly, attrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World History</td>\n",
       "      <td>Indus Valley Civilization: Crash Course World ...</td>\n",
       "      <td>Hi, I’m John Green, and this is Crash Course W...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=n7ndRwqJYDM&amp;li...</td>\n",
       "      <td>(Hi, ,, I, ’m, John, Green, ,, and, this, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World History</td>\n",
       "      <td>Christianity from Judaism to Constantine: Cras...</td>\n",
       "      <td>Hi there my name’s John Green; this is Crash C...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TG55ErfdaeY&amp;li...</td>\n",
       "      <td>(Hi, there, my, name, ’s, John, Green, ;, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World History</td>\n",
       "      <td>Fall of The Roman Empire...in the 15th Century...</td>\n",
       "      <td>Hi there, my name’s John Green; this is Crash ...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=3PszVWZNWVA&amp;li...</td>\n",
       "      <td>(Hi, there, ,, my, name, ’s, John, Green, ;, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World History</td>\n",
       "      <td>Islam, the Quran, and the Five Pillars: Crash ...</td>\n",
       "      <td>Hi there, I’m John Green, this is Crash Course...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TpcbfxtdoI8&amp;li...</td>\n",
       "      <td>(Hi, there, ,, I, ’m, John, Green, ,, this, is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject                                              Title  \\\n",
       "0  World History  The Agricultural Revolution: Crash Course Worl...   \n",
       "1  World History  Indus Valley Civilization: Crash Course World ...   \n",
       "2  World History  Christianity from Judaism to Constantine: Cras...   \n",
       "3  World History  Fall of The Roman Empire...in the 15th Century...   \n",
       "4  World History  Islam, the Quran, and the Five Pillars: Crash ...   \n",
       "\n",
       "                                                Text Publish Time  \\\n",
       "0  Hello, learned and astonishingly attractive pu...   2012-01-26   \n",
       "1  Hi, I’m John Green, and this is Crash Course W...   2012-01-26   \n",
       "2  Hi there my name’s John Green; this is Crash C...   2012-01-26   \n",
       "3  Hi there, my name’s John Green; this is Crash ...   2012-01-26   \n",
       "4  Hi there, I’m John Green, this is Crash Course...   2012-01-26   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.youtube.com/watch?v=Yocja_N5s1I&li...   \n",
       "1  https://www.youtube.com/watch?v=n7ndRwqJYDM&li...   \n",
       "2  https://www.youtube.com/watch?v=TG55ErfdaeY&li...   \n",
       "3  https://www.youtube.com/watch?v=3PszVWZNWVA&li...   \n",
       "4  https://www.youtube.com/watch?v=TpcbfxtdoI8&li...   \n",
       "\n",
       "                                            Doc Text  \n",
       "0  (Hello, ,, learned, and, astonishingly, attrac...  \n",
       "1  (Hi, ,, I, ’m, John, Green, ,, and, this, is, ...  \n",
       "2  (Hi, there, my, name, ’s, John, Green, ;, this...  \n",
       "3  (Hi, there, ,, my, name, ’s, John, Green, ;, t...  \n",
       "4  (Hi, there, ,, I, ’m, John, Green, ,, this, is...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Doc Text\"] = df[\"Text\"].map(nlp)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a18521c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sentence(tokenized_sent, stopword_removal=True, punctuation_removal=True, lower_case=False, lemmatize=True, minimum_length=2):\n",
    "    normalized_sent = tokenized_sent\n",
    "    \n",
    "    if(stopword_removal):\n",
    "        normalized_sent = [token for token in normalized_sent\n",
    "                            if not(token.is_stop)]\n",
    "    if (punctuation_removal):\n",
    "        normalized_sent = [token for token in normalized_sent\n",
    "                            if not(token.is_punct)]\n",
    "    if (lower_case):\n",
    "        normalized_sent = [token.text.lower() for token in normalized_sent]\n",
    "    \n",
    "    if (minimum_length > 1):\n",
    "        normalized_sent = [token for token in normalized_sent\n",
    "                            if len(token)>minimum_length]\n",
    "    if (lemmatize):\n",
    "        normalized_sent = [token.lemma_ for token in normalized_sent]\n",
    "\n",
    "    return normalized_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daa1a719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Publish Time</th>\n",
       "      <th>URL</th>\n",
       "      <th>Doc Text</th>\n",
       "      <th>Normalized Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World History</td>\n",
       "      <td>The Agricultural Revolution: Crash Course Worl...</td>\n",
       "      <td>Hello, learned and astonishingly attractive pu...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=Yocja_N5s1I&amp;li...</td>\n",
       "      <td>(Hello, ,, learned, and, astonishingly, attrac...</td>\n",
       "      <td>[hello, learn, astonishingly, attractive, pupi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World History</td>\n",
       "      <td>Indus Valley Civilization: Crash Course World ...</td>\n",
       "      <td>Hi, I’m John Green, and this is Crash Course W...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=n7ndRwqJYDM&amp;li...</td>\n",
       "      <td>(Hi, ,, I, ’m, John, Green, ,, and, this, is, ...</td>\n",
       "      <td>[John, Green, Crash, course, world, history, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World History</td>\n",
       "      <td>Christianity from Judaism to Constantine: Cras...</td>\n",
       "      <td>Hi there my name’s John Green; this is Crash C...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TG55ErfdaeY&amp;li...</td>\n",
       "      <td>(Hi, there, my, name, ’s, John, Green, ;, this...</td>\n",
       "      <td>[John, Green, Crash, course, World, history, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World History</td>\n",
       "      <td>Fall of The Roman Empire...in the 15th Century...</td>\n",
       "      <td>Hi there, my name’s John Green; this is Crash ...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=3PszVWZNWVA&amp;li...</td>\n",
       "      <td>(Hi, there, ,, my, name, ’s, John, Green, ;, t...</td>\n",
       "      <td>[John, Green, Crash, course, World, History, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World History</td>\n",
       "      <td>Islam, the Quran, and the Five Pillars: Crash ...</td>\n",
       "      <td>Hi there, I’m John Green, this is Crash Course...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TpcbfxtdoI8&amp;li...</td>\n",
       "      <td>(Hi, there, ,, I, ’m, John, Green, ,, this, is...</td>\n",
       "      <td>[John, Green, Crash, course, World, History, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject                                              Title  \\\n",
       "0  World History  The Agricultural Revolution: Crash Course Worl...   \n",
       "1  World History  Indus Valley Civilization: Crash Course World ...   \n",
       "2  World History  Christianity from Judaism to Constantine: Cras...   \n",
       "3  World History  Fall of The Roman Empire...in the 15th Century...   \n",
       "4  World History  Islam, the Quran, and the Five Pillars: Crash ...   \n",
       "\n",
       "                                                Text Publish Time  \\\n",
       "0  Hello, learned and astonishingly attractive pu...   2012-01-26   \n",
       "1  Hi, I’m John Green, and this is Crash Course W...   2012-01-26   \n",
       "2  Hi there my name’s John Green; this is Crash C...   2012-01-26   \n",
       "3  Hi there, my name’s John Green; this is Crash ...   2012-01-26   \n",
       "4  Hi there, I’m John Green, this is Crash Course...   2012-01-26   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.youtube.com/watch?v=Yocja_N5s1I&li...   \n",
       "1  https://www.youtube.com/watch?v=n7ndRwqJYDM&li...   \n",
       "2  https://www.youtube.com/watch?v=TG55ErfdaeY&li...   \n",
       "3  https://www.youtube.com/watch?v=3PszVWZNWVA&li...   \n",
       "4  https://www.youtube.com/watch?v=TpcbfxtdoI8&li...   \n",
       "\n",
       "                                            Doc Text  \\\n",
       "0  (Hello, ,, learned, and, astonishingly, attrac...   \n",
       "1  (Hi, ,, I, ’m, John, Green, ,, and, this, is, ...   \n",
       "2  (Hi, there, my, name, ’s, John, Green, ;, this...   \n",
       "3  (Hi, there, ,, my, name, ’s, John, Green, ;, t...   \n",
       "4  (Hi, there, ,, I, ’m, John, Green, ,, this, is...   \n",
       "\n",
       "                                    Normalized Words  \n",
       "0  [hello, learn, astonishingly, attractive, pupi...  \n",
       "1  [John, Green, Crash, course, world, history, l...  \n",
       "2  [John, Green, Crash, course, World, history, t...  \n",
       "3  [John, Green, Crash, course, World, History, t...  \n",
       "4  [John, Green, Crash, course, World, History, t...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Normalized Words\"] = df[\"Doc Text\"].map(normalize_sentence)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb6544",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۷. تحلیل فرکانس کلمات\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536bdf8",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "ابتدا رایج‌ترین کلمات فارغ از نقش دستوری آنها، برای هر متن در ستون Frequent Words بدست آمد. سپس متن‌ها با توجه به موضوع تجمیع شدند و رایج‌ترین کلمات آنها در دیتافریم frequent_subject_words ذخیره شد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13faafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_frequent_words(normalized_sent, n=20):\n",
    "    frequent_words = Counter(str(normalized_sent).split(\", \")).most_common(n)\n",
    "    return frequent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "381ffaa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Publish Time</th>\n",
       "      <th>URL</th>\n",
       "      <th>Doc Text</th>\n",
       "      <th>Normalized Words</th>\n",
       "      <th>Frequent Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World History</td>\n",
       "      <td>The Agricultural Revolution: Crash Course Worl...</td>\n",
       "      <td>Hello, learned and astonishingly attractive pu...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=Yocja_N5s1I&amp;li...</td>\n",
       "      <td>(Hello, ,, learned, and, astonishingly, attrac...</td>\n",
       "      <td>[hello, learn, astonishingly, attractive, pupi...</td>\n",
       "      <td>[('like', 14), ('agriculture', 13), ('people',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World History</td>\n",
       "      <td>Indus Valley Civilization: Crash Course World ...</td>\n",
       "      <td>Hi, I’m John Green, and this is Crash Course W...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=n7ndRwqJYDM&amp;li...</td>\n",
       "      <td>(Hi, ,, I, ’m, John, Green, ,, and, this, is, ...</td>\n",
       "      <td>[John, Green, Crash, course, world, history, l...</td>\n",
       "      <td>[('civilization', 20), ('know', 14), ('Indus',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World History</td>\n",
       "      <td>Christianity from Judaism to Constantine: Cras...</td>\n",
       "      <td>Hi there my name’s John Green; this is Crash C...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TG55ErfdaeY&amp;li...</td>\n",
       "      <td>(Hi, there, my, name, ’s, John, Green, ;, this...</td>\n",
       "      <td>[John, Green, Crash, course, World, history, t...</td>\n",
       "      <td>[('Jesus', 28), ('Jews', 17), ('time', 16), ('...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World History</td>\n",
       "      <td>Fall of The Roman Empire...in the 15th Century...</td>\n",
       "      <td>Hi there, my name’s John Green; this is Crash ...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=3PszVWZNWVA&amp;li...</td>\n",
       "      <td>(Hi, there, ,, my, name, ’s, John, Green, ;, t...</td>\n",
       "      <td>[John, Green, Crash, course, World, History, t...</td>\n",
       "      <td>[('Rome', 24), ('Empire', 16), ('Roman', 14), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World History</td>\n",
       "      <td>Islam, the Quran, and the Five Pillars: Crash ...</td>\n",
       "      <td>Hi there, I’m John Green, this is Crash Course...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TpcbfxtdoI8&amp;li...</td>\n",
       "      <td>(Hi, there, ,, I, ’m, John, Green, ,, this, is...</td>\n",
       "      <td>[John, Green, Crash, course, World, History, t...</td>\n",
       "      <td>[('like', 24), ('Muhammad', 21), ('people', 18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject                                              Title  \\\n",
       "0  World History  The Agricultural Revolution: Crash Course Worl...   \n",
       "1  World History  Indus Valley Civilization: Crash Course World ...   \n",
       "2  World History  Christianity from Judaism to Constantine: Cras...   \n",
       "3  World History  Fall of The Roman Empire...in the 15th Century...   \n",
       "4  World History  Islam, the Quran, and the Five Pillars: Crash ...   \n",
       "\n",
       "                                                Text Publish Time  \\\n",
       "0  Hello, learned and astonishingly attractive pu...   2012-01-26   \n",
       "1  Hi, I’m John Green, and this is Crash Course W...   2012-01-26   \n",
       "2  Hi there my name’s John Green; this is Crash C...   2012-01-26   \n",
       "3  Hi there, my name’s John Green; this is Crash ...   2012-01-26   \n",
       "4  Hi there, I’m John Green, this is Crash Course...   2012-01-26   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.youtube.com/watch?v=Yocja_N5s1I&li...   \n",
       "1  https://www.youtube.com/watch?v=n7ndRwqJYDM&li...   \n",
       "2  https://www.youtube.com/watch?v=TG55ErfdaeY&li...   \n",
       "3  https://www.youtube.com/watch?v=3PszVWZNWVA&li...   \n",
       "4  https://www.youtube.com/watch?v=TpcbfxtdoI8&li...   \n",
       "\n",
       "                                            Doc Text  \\\n",
       "0  (Hello, ,, learned, and, astonishingly, attrac...   \n",
       "1  (Hi, ,, I, ’m, John, Green, ,, and, this, is, ...   \n",
       "2  (Hi, there, my, name, ’s, John, Green, ;, this...   \n",
       "3  (Hi, there, ,, my, name, ’s, John, Green, ;, t...   \n",
       "4  (Hi, there, ,, I, ’m, John, Green, ,, this, is...   \n",
       "\n",
       "                                    Normalized Words  \\\n",
       "0  [hello, learn, astonishingly, attractive, pupi...   \n",
       "1  [John, Green, Crash, course, world, history, l...   \n",
       "2  [John, Green, Crash, course, World, history, t...   \n",
       "3  [John, Green, Crash, course, World, History, t...   \n",
       "4  [John, Green, Crash, course, World, History, t...   \n",
       "\n",
       "                                      Frequent Words  \n",
       "0  [('like', 14), ('agriculture', 13), ('people',...  \n",
       "1  [('civilization', 20), ('know', 14), ('Indus',...  \n",
       "2  [('Jesus', 28), ('Jews', 17), ('time', 16), ('...  \n",
       "3  [('Rome', 24), ('Empire', 16), ('Roman', 14), ...  \n",
       "4  [('like', 24), ('Muhammad', 21), ('people', 18...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Frequent Words\"] = df[\"Normalized Words\"].map(get_frequent_words)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0aa66802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subject\n",
       "Computer Science    [[hello, world, Carrie, Anne, Philbin, welcome...\n",
       "Economics           [[today, peer, world, shadowy, government, sto...\n",
       "Philosophy          [[get, new, set, new, prop, like, friend, Niet...\n",
       "Psychology          [[hello, welcome, new, set, chaise, lounge, ch...\n",
       "Sociology           [[hello, Hank, Nicole, usually, scene, member,...\n",
       "Name: Normalized Words, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_words = df.groupby(\"Subject\")['Normalized Words'].apply(list)\n",
    "subject_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dcd8d8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Economics</th>\n",
       "      <th>Philosophy</th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Sociology</th>\n",
       "      <th>World History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('computer', 709)</td>\n",
       "      <td>('price', 351)</td>\n",
       "      <td>('like', 526)</td>\n",
       "      <td>('like', 521)</td>\n",
       "      <td>('people', 527)</td>\n",
       "      <td>('like', 466)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('like', 628)</td>\n",
       "      <td>('people', 339)</td>\n",
       "      <td>('think', 411)</td>\n",
       "      <td>('brain', 269)</td>\n",
       "      <td>('society', 493)</td>\n",
       "      <td>('people', 325)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('call', 298)</td>\n",
       "      <td>('like', 317)</td>\n",
       "      <td>('know', 378)</td>\n",
       "      <td>('people', 246)</td>\n",
       "      <td>('social', 482)</td>\n",
       "      <td>('history', 273)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('datum', 281)</td>\n",
       "      <td>('money', 274)</td>\n",
       "      <td>('thing', 355)</td>\n",
       "      <td>('thing', 206)</td>\n",
       "      <td>('like', 461)</td>\n",
       "      <td>('course', 218)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('memory', 259)</td>\n",
       "      <td>('government', 256)</td>\n",
       "      <td>('people', 308)</td>\n",
       "      <td>('disorder', 203)</td>\n",
       "      <td>('group', 273)</td>\n",
       "      <td>('know', 217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('time', 248)</td>\n",
       "      <td>('economy', 244)</td>\n",
       "      <td>('God', 288)</td>\n",
       "      <td>('way', 197)</td>\n",
       "      <td>('work', 249)</td>\n",
       "      <td>('good', 217)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('program', 245)</td>\n",
       "      <td>('economist', 238)</td>\n",
       "      <td>('way', 276)</td>\n",
       "      <td>('behavior', 190)</td>\n",
       "      <td>('different', 240)</td>\n",
       "      <td>('week', 207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('number', 234)</td>\n",
       "      <td>('market', 236)</td>\n",
       "      <td>('say', 269)</td>\n",
       "      <td>('think', 182)</td>\n",
       "      <td>('class', 233)</td>\n",
       "      <td>('world', 203)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('bit', 226)</td>\n",
       "      <td>('economic', 231)</td>\n",
       "      <td>('time', 248)</td>\n",
       "      <td>('time', 171)</td>\n",
       "      <td>('course', 216)</td>\n",
       "      <td>('war', 203)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('use', 217)</td>\n",
       "      <td>('country', 226)</td>\n",
       "      <td>('good', 242)</td>\n",
       "      <td>('know', 169)</td>\n",
       "      <td>('way', 214)</td>\n",
       "      <td>('mean', 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('value', 212)</td>\n",
       "      <td>('cost', 222)</td>\n",
       "      <td>('world', 235)</td>\n",
       "      <td>('different', 149)</td>\n",
       "      <td>('family', 209)</td>\n",
       "      <td>('time', 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('example', 205)</td>\n",
       "      <td>('high', 186)</td>\n",
       "      <td>('mean', 224)</td>\n",
       "      <td>('learn', 147)</td>\n",
       "      <td>('school', 195)</td>\n",
       "      <td>('way', 197)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('need', 192)</td>\n",
       "      <td>('help', 181)</td>\n",
       "      <td>('life', 214)</td>\n",
       "      <td>('work', 137)</td>\n",
       "      <td>('thing', 188)</td>\n",
       "      <td>('go', 180)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('let', 187)</td>\n",
       "      <td>('pay', 176)</td>\n",
       "      <td>('belief', 188)</td>\n",
       "      <td>('lot', 134)</td>\n",
       "      <td>('woman', 186)</td>\n",
       "      <td>('trade', 180)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('code', 174)</td>\n",
       "      <td>('produce', 175)</td>\n",
       "      <td>('Squarespace', 179)</td>\n",
       "      <td>('help', 134)</td>\n",
       "      <td>('gender', 185)</td>\n",
       "      <td>('today', 175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('thing', 173)</td>\n",
       "      <td>('good', 174)</td>\n",
       "      <td>('argument', 179)</td>\n",
       "      <td>('memory', 133)</td>\n",
       "      <td>('example', 181)</td>\n",
       "      <td>('Green', 169)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>('machine', 171)</td>\n",
       "      <td>('want', 167)</td>\n",
       "      <td>('philosopher', 177)</td>\n",
       "      <td>('feel', 121)</td>\n",
       "      <td>('theory', 179)</td>\n",
       "      <td>('thank', 166)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>('go', 168)</td>\n",
       "      <td>('go', 155)</td>\n",
       "      <td>('go', 176)</td>\n",
       "      <td>('kind', 121)</td>\n",
       "      <td>('system', 175)</td>\n",
       "      <td>('thing', 155)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>('know', 168)</td>\n",
       "      <td>('buy', 150)</td>\n",
       "      <td>('person', 168)</td>\n",
       "      <td>('call', 118)</td>\n",
       "      <td>('mean', 172)</td>\n",
       "      <td>('let', 155)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>('store', 168)</td>\n",
       "      <td>('let', 148)</td>\n",
       "      <td>('right', 167)</td>\n",
       "      <td>('come', 115)</td>\n",
       "      <td>('talk', 169)</td>\n",
       "      <td>('call', 150)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Computer Science            Economics            Philosophy  \\\n",
       "0   ('computer', 709)       ('price', 351)         ('like', 526)   \n",
       "1       ('like', 628)      ('people', 339)        ('think', 411)   \n",
       "2       ('call', 298)        ('like', 317)         ('know', 378)   \n",
       "3      ('datum', 281)       ('money', 274)        ('thing', 355)   \n",
       "4     ('memory', 259)  ('government', 256)       ('people', 308)   \n",
       "5       ('time', 248)     ('economy', 244)          ('God', 288)   \n",
       "6    ('program', 245)   ('economist', 238)          ('way', 276)   \n",
       "7     ('number', 234)      ('market', 236)          ('say', 269)   \n",
       "8        ('bit', 226)    ('economic', 231)         ('time', 248)   \n",
       "9        ('use', 217)     ('country', 226)         ('good', 242)   \n",
       "10     ('value', 212)        ('cost', 222)        ('world', 235)   \n",
       "11   ('example', 205)        ('high', 186)         ('mean', 224)   \n",
       "12      ('need', 192)        ('help', 181)         ('life', 214)   \n",
       "13       ('let', 187)         ('pay', 176)       ('belief', 188)   \n",
       "14      ('code', 174)     ('produce', 175)  ('Squarespace', 179)   \n",
       "15     ('thing', 173)        ('good', 174)     ('argument', 179)   \n",
       "16   ('machine', 171)        ('want', 167)  ('philosopher', 177)   \n",
       "17        ('go', 168)          ('go', 155)           ('go', 176)   \n",
       "18      ('know', 168)         ('buy', 150)       ('person', 168)   \n",
       "19     ('store', 168)         ('let', 148)        ('right', 167)   \n",
       "\n",
       "            Psychology           Sociology     World History  \n",
       "0        ('like', 521)     ('people', 527)     ('like', 466)  \n",
       "1       ('brain', 269)    ('society', 493)   ('people', 325)  \n",
       "2      ('people', 246)     ('social', 482)  ('history', 273)  \n",
       "3       ('thing', 206)       ('like', 461)   ('course', 218)  \n",
       "4    ('disorder', 203)      ('group', 273)     ('know', 217)  \n",
       "5         ('way', 197)       ('work', 249)     ('good', 217)  \n",
       "6    ('behavior', 190)  ('different', 240)     ('week', 207)  \n",
       "7       ('think', 182)      ('class', 233)    ('world', 203)  \n",
       "8        ('time', 171)     ('course', 216)      ('war', 203)  \n",
       "9        ('know', 169)        ('way', 214)     ('mean', 200)  \n",
       "10  ('different', 149)     ('family', 209)     ('time', 200)  \n",
       "11      ('learn', 147)     ('school', 195)      ('way', 197)  \n",
       "12       ('work', 137)      ('thing', 188)       ('go', 180)  \n",
       "13        ('lot', 134)      ('woman', 186)    ('trade', 180)  \n",
       "14       ('help', 134)     ('gender', 185)    ('today', 175)  \n",
       "15     ('memory', 133)    ('example', 181)    ('Green', 169)  \n",
       "16       ('feel', 121)     ('theory', 179)    ('thank', 166)  \n",
       "17       ('kind', 121)     ('system', 175)    ('thing', 155)  \n",
       "18       ('call', 118)       ('mean', 172)      ('let', 155)  \n",
       "19       ('come', 115)       ('talk', 169)     ('call', 150)  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_subject_words = subject_words.map(get_frequent_words)\n",
    "frequent_subject_words = pd.DataFrame(frequent_subject_words.to_dict())\n",
    "frequent_subject_words.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b689a9",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "سپس کلمات رایج نقش‌های دستوری مهم Noun و Proper Noun و Adjective و Adverb و Verb برای هر متن در ستون‌های مرتبطشان قرار گرفتند. نهایتا متن‌ها با توجه به موضوع تجمیع شدند و در دیکشنری frequent_pos_words رایج‌ترین کلمات هر نقش دستوری در دیتافریم مخصوص به خودشان ذخیره شد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ff03b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normalized NOUNs', 'Normalized PROPNs', 'Normalized ADJs', 'Normalized ADVs', 'Normalized VERBs']\n"
     ]
    }
   ],
   "source": [
    "pos_tags = ['NOUN', 'PROPN', 'ADJ', 'ADV', 'VERB']\n",
    "columns = [f'Normalized {pos}s' for pos in pos_tags]\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c26c1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Publish Time</th>\n",
       "      <th>URL</th>\n",
       "      <th>Doc Text</th>\n",
       "      <th>Normalized Words</th>\n",
       "      <th>Frequent Words</th>\n",
       "      <th>Normalized NOUNs</th>\n",
       "      <th>Normalized PROPNs</th>\n",
       "      <th>Normalized ADJs</th>\n",
       "      <th>Normalized ADVs</th>\n",
       "      <th>Normalized VERBs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>World History</td>\n",
       "      <td>The Agricultural Revolution: Crash Course Worl...</td>\n",
       "      <td>Hello, learned and astonishingly attractive pu...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=Yocja_N5s1I&amp;li...</td>\n",
       "      <td>(Hello, ,, learned, and, astonishingly, attrac...</td>\n",
       "      <td>[hello, learn, astonishingly, attractive, pupi...</td>\n",
       "      <td>[('like', 14), ('agriculture', 13), ('people',...</td>\n",
       "      <td>[pupil, course, world, history, week, year, hu...</td>\n",
       "      <td>[John, Green, Crash, Mr., Green, Mr., Green, T...</td>\n",
       "      <td>[attractive, mere, productive, political, able...</td>\n",
       "      <td>[astonishingly, easily, importantly, strictly,...</td>\n",
       "      <td>[learn, want, welcome, learn, go, hunt, going,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>World History</td>\n",
       "      <td>Indus Valley Civilization: Crash Course World ...</td>\n",
       "      <td>Hi, I’m John Green, and this is Crash Course W...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=n7ndRwqJYDM&amp;li...</td>\n",
       "      <td>(Hi, ,, I, ’m, John, Green, ,, and, this, is, ...</td>\n",
       "      <td>[John, Green, Crash, course, world, history, l...</td>\n",
       "      <td>[('civilization', 20), ('know', 14), ('Indus',...</td>\n",
       "      <td>[course, world, history, today, question, eye,...</td>\n",
       "      <td>[John, Green, Crash, Mr., Green, Mr., Green, C...</td>\n",
       "      <td>[alive, well, nice, attractive, terrible, prob...</td>\n",
       "      <td>[insanely, possibly, momentarily, generally, b...</td>\n",
       "      <td>[begin, answer, end, organize, value, behave, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World History</td>\n",
       "      <td>Christianity from Judaism to Constantine: Cras...</td>\n",
       "      <td>Hi there my name’s John Green; this is Crash C...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TG55ErfdaeY&amp;li...</td>\n",
       "      <td>(Hi, there, my, name, ’s, John, Green, ;, this...</td>\n",
       "      <td>[John, Green, Crash, course, World, history, t...</td>\n",
       "      <td>[('Jesus', 28), ('Jews', 17), ('time', 16), ('...</td>\n",
       "      <td>[course, history, today, coin, time, emperor, ...</td>\n",
       "      <td>[John, Green, Crash, World, Jesus, Jesus, Roma...</td>\n",
       "      <td>[roman, unusual, poor, jewish, roman, messiani...</td>\n",
       "      <td>[straight, initially, eventually, kind, thou, ...</td>\n",
       "      <td>[go, talk, bear, call, let, state, start, bear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World History</td>\n",
       "      <td>Fall of The Roman Empire...in the 15th Century...</td>\n",
       "      <td>Hi there, my name’s John Green; this is Crash ...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=3PszVWZNWVA&amp;li...</td>\n",
       "      <td>(Hi, there, ,, my, name, ’s, John, Green, ;, t...</td>\n",
       "      <td>[John, Green, Crash, course, World, History, t...</td>\n",
       "      <td>[('Rome', 24), ('Empire', 16), ('Roman', 14), ...</td>\n",
       "      <td>[course, today, fall, lady, lady, past, minute...</td>\n",
       "      <td>[John, Green, Crash, World, History, Rome, Mr....</td>\n",
       "      <td>[pretty, considerable, historical, 15th, tradi...</td>\n",
       "      <td>[fully, notably, probably, exactly, soon, outs...</td>\n",
       "      <td>[go, talk, fall, remain, go, argue, fall, let,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World History</td>\n",
       "      <td>Islam, the Quran, and the Five Pillars: Crash ...</td>\n",
       "      <td>Hi there, I’m John Green, this is Crash Course...</td>\n",
       "      <td>2012-01-26</td>\n",
       "      <td>https://www.youtube.com/watch?v=TpcbfxtdoI8&amp;li...</td>\n",
       "      <td>(Hi, there, ,, I, ’m, John, Green, ,, this, is...</td>\n",
       "      <td>[John, Green, Crash, course, World, History, t...</td>\n",
       "      <td>[('like', 24), ('Muhammad', 21), ('people', 18...</td>\n",
       "      <td>[course, today, coast, instance, people, histo...</td>\n",
       "      <td>[John, Green, Crash, World, History, Islam, Ch...</td>\n",
       "      <td>[little, islamic, interesting, non, annoying, ...</td>\n",
       "      <td>[terribly, probably, probably, initially, slow...</td>\n",
       "      <td>[go, talk, grow, understand, know, know, googl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subject                                              Title  \\\n",
       "0  World History  The Agricultural Revolution: Crash Course Worl...   \n",
       "1  World History  Indus Valley Civilization: Crash Course World ...   \n",
       "2  World History  Christianity from Judaism to Constantine: Cras...   \n",
       "3  World History  Fall of The Roman Empire...in the 15th Century...   \n",
       "4  World History  Islam, the Quran, and the Five Pillars: Crash ...   \n",
       "\n",
       "                                                Text Publish Time  \\\n",
       "0  Hello, learned and astonishingly attractive pu...   2012-01-26   \n",
       "1  Hi, I’m John Green, and this is Crash Course W...   2012-01-26   \n",
       "2  Hi there my name’s John Green; this is Crash C...   2012-01-26   \n",
       "3  Hi there, my name’s John Green; this is Crash ...   2012-01-26   \n",
       "4  Hi there, I’m John Green, this is Crash Course...   2012-01-26   \n",
       "\n",
       "                                                 URL  \\\n",
       "0  https://www.youtube.com/watch?v=Yocja_N5s1I&li...   \n",
       "1  https://www.youtube.com/watch?v=n7ndRwqJYDM&li...   \n",
       "2  https://www.youtube.com/watch?v=TG55ErfdaeY&li...   \n",
       "3  https://www.youtube.com/watch?v=3PszVWZNWVA&li...   \n",
       "4  https://www.youtube.com/watch?v=TpcbfxtdoI8&li...   \n",
       "\n",
       "                                            Doc Text  \\\n",
       "0  (Hello, ,, learned, and, astonishingly, attrac...   \n",
       "1  (Hi, ,, I, ’m, John, Green, ,, and, this, is, ...   \n",
       "2  (Hi, there, my, name, ’s, John, Green, ;, this...   \n",
       "3  (Hi, there, ,, my, name, ’s, John, Green, ;, t...   \n",
       "4  (Hi, there, ,, I, ’m, John, Green, ,, this, is...   \n",
       "\n",
       "                                    Normalized Words  \\\n",
       "0  [hello, learn, astonishingly, attractive, pupi...   \n",
       "1  [John, Green, Crash, course, world, history, l...   \n",
       "2  [John, Green, Crash, course, World, history, t...   \n",
       "3  [John, Green, Crash, course, World, History, t...   \n",
       "4  [John, Green, Crash, course, World, History, t...   \n",
       "\n",
       "                                      Frequent Words  \\\n",
       "0  [('like', 14), ('agriculture', 13), ('people',...   \n",
       "1  [('civilization', 20), ('know', 14), ('Indus',...   \n",
       "2  [('Jesus', 28), ('Jews', 17), ('time', 16), ('...   \n",
       "3  [('Rome', 24), ('Empire', 16), ('Roman', 14), ...   \n",
       "4  [('like', 24), ('Muhammad', 21), ('people', 18...   \n",
       "\n",
       "                                    Normalized NOUNs  \\\n",
       "0  [pupil, course, world, history, week, year, hu...   \n",
       "1  [course, world, history, today, question, eye,...   \n",
       "2  [course, history, today, coin, time, emperor, ...   \n",
       "3  [course, today, fall, lady, lady, past, minute...   \n",
       "4  [course, today, coast, instance, people, histo...   \n",
       "\n",
       "                                   Normalized PROPNs  \\\n",
       "0  [John, Green, Crash, Mr., Green, Mr., Green, T...   \n",
       "1  [John, Green, Crash, Mr., Green, Mr., Green, C...   \n",
       "2  [John, Green, Crash, World, Jesus, Jesus, Roma...   \n",
       "3  [John, Green, Crash, World, History, Rome, Mr....   \n",
       "4  [John, Green, Crash, World, History, Islam, Ch...   \n",
       "\n",
       "                                     Normalized ADJs  \\\n",
       "0  [attractive, mere, productive, political, able...   \n",
       "1  [alive, well, nice, attractive, terrible, prob...   \n",
       "2  [roman, unusual, poor, jewish, roman, messiani...   \n",
       "3  [pretty, considerable, historical, 15th, tradi...   \n",
       "4  [little, islamic, interesting, non, annoying, ...   \n",
       "\n",
       "                                     Normalized ADVs  \\\n",
       "0  [astonishingly, easily, importantly, strictly,...   \n",
       "1  [insanely, possibly, momentarily, generally, b...   \n",
       "2  [straight, initially, eventually, kind, thou, ...   \n",
       "3  [fully, notably, probably, exactly, soon, outs...   \n",
       "4  [terribly, probably, probably, initially, slow...   \n",
       "\n",
       "                                    Normalized VERBs  \n",
       "0  [learn, want, welcome, learn, go, hunt, going,...  \n",
       "1  [begin, answer, end, organize, value, behave, ...  \n",
       "2  [go, talk, bear, call, let, state, start, bear...  \n",
       "3  [go, talk, fall, remain, go, argue, fall, let,...  \n",
       "4  [go, talk, grow, understand, know, know, googl...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pos_words(tokens, pos):\n",
    "    pos_words = [token for token in tokens if token.pos_ == pos]\n",
    "    normalized_pos_words = normalize_sentence(pos_words)\n",
    "    return normalized_pos_words\n",
    "\n",
    "for pos in pos_tags:\n",
    "    df[f'Normalized {pos}s'] = df['Doc Text'].apply(get_pos_words, pos=pos)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f77425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_pos_words = dict()\n",
    "for pos in pos_tags:\n",
    "    pos_words = df.groupby(\"Subject\")[f'Normalized {pos}s'].apply(list)\n",
    "    frequent_pos_words[pos] = pos_words.map(get_frequent_words)\n",
    "    frequent_pos_words[pos] = pd.DataFrame(frequent_pos_words[pos].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cace3f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Economics</th>\n",
       "      <th>Philosophy</th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Sociology</th>\n",
       "      <th>World History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('computer', 706)</td>\n",
       "      <td>('people', 339)</td>\n",
       "      <td>('thing', 355)</td>\n",
       "      <td>('brain', 268)</td>\n",
       "      <td>('people', 525)</td>\n",
       "      <td>('people', 325)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('datum', 281)</td>\n",
       "      <td>('price', 338)</td>\n",
       "      <td>('people', 303)</td>\n",
       "      <td>('people', 245)</td>\n",
       "      <td>('society', 493)</td>\n",
       "      <td>('history', 273)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('memory', 259)</td>\n",
       "      <td>('money', 273)</td>\n",
       "      <td>('way', 273)</td>\n",
       "      <td>('thing', 205)</td>\n",
       "      <td>('group', 270)</td>\n",
       "      <td>('week', 207)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('time', 246)</td>\n",
       "      <td>('government', 256)</td>\n",
       "      <td>('time', 248)</td>\n",
       "      <td>('disorder', 203)</td>\n",
       "      <td>('class', 231)</td>\n",
       "      <td>('world', 203)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('number', 233)</td>\n",
       "      <td>('economy', 244)</td>\n",
       "      <td>('world', 233)</td>\n",
       "      <td>('way', 194)</td>\n",
       "      <td>('way', 211)</td>\n",
       "      <td>('time', 200)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('program', 232)</td>\n",
       "      <td>('economist', 238)</td>\n",
       "      <td>('life', 214)</td>\n",
       "      <td>('behavior', 190)</td>\n",
       "      <td>('family', 209)</td>\n",
       "      <td>('way', 194)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('bit', 226)</td>\n",
       "      <td>('market', 236)</td>\n",
       "      <td>('belief', 188)</td>\n",
       "      <td>('time', 171)</td>\n",
       "      <td>('course', 206)</td>\n",
       "      <td>('war', 194)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('value', 212)</td>\n",
       "      <td>('country', 226)</td>\n",
       "      <td>('argument', 179)</td>\n",
       "      <td>('lot', 134)</td>\n",
       "      <td>('school', 193)</td>\n",
       "      <td>('today', 175)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('example', 205)</td>\n",
       "      <td>('cost', 203)</td>\n",
       "      <td>('philosopher', 176)</td>\n",
       "      <td>('memory', 133)</td>\n",
       "      <td>('thing', 188)</td>\n",
       "      <td>('course', 169)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('thing', 173)</td>\n",
       "      <td>('thing', 142)</td>\n",
       "      <td>('person', 167)</td>\n",
       "      <td>('personality', 111)</td>\n",
       "      <td>('woman', 186)</td>\n",
       "      <td>('thing', 155)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('machine', 171)</td>\n",
       "      <td>('income', 138)</td>\n",
       "      <td>('word', 144)</td>\n",
       "      <td>('kind', 105)</td>\n",
       "      <td>('gender', 185)</td>\n",
       "      <td>('thank', 144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('code', 167)</td>\n",
       "      <td>('time', 135)</td>\n",
       "      <td>('course', 137)</td>\n",
       "      <td>('group', 103)</td>\n",
       "      <td>('example', 181)</td>\n",
       "      <td>('trade', 143)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('instruction', 154)</td>\n",
       "      <td>('worker', 128)</td>\n",
       "      <td>('idea', 120)</td>\n",
       "      <td>('episode', 98)</td>\n",
       "      <td>('theory', 179)</td>\n",
       "      <td>('lot', 142)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('way', 149)</td>\n",
       "      <td>('year', 126)</td>\n",
       "      <td>('episode', 118)</td>\n",
       "      <td>('emotion', 97)</td>\n",
       "      <td>('system', 175)</td>\n",
       "      <td>('year', 139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('system', 129)</td>\n",
       "      <td>('economic', 115)</td>\n",
       "      <td>('question', 115)</td>\n",
       "      <td>('mind', 94)</td>\n",
       "      <td>('time', 162)</td>\n",
       "      <td>('century', 139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('today', 118)</td>\n",
       "      <td>('lot', 108)</td>\n",
       "      <td>('theory', 115)</td>\n",
       "      <td>('person', 94)</td>\n",
       "      <td>('culture', 160)</td>\n",
       "      <td>('slave', 122)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>('line', 112)</td>\n",
       "      <td>('business', 106)</td>\n",
       "      <td>('lot', 101)</td>\n",
       "      <td>('psychologist', 91)</td>\n",
       "      <td>('income', 159)</td>\n",
       "      <td>('empire', 120)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>('people', 111)</td>\n",
       "      <td>('dollar', 106)</td>\n",
       "      <td>('view', 100)</td>\n",
       "      <td>('psychology', 90)</td>\n",
       "      <td>('race', 153)</td>\n",
       "      <td>('idea', 105)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>('file', 111)</td>\n",
       "      <td>('supply', 105)</td>\n",
       "      <td>('case', 97)</td>\n",
       "      <td>('life', 90)</td>\n",
       "      <td>('country', 145)</td>\n",
       "      <td>('life', 104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>('level', 102)</td>\n",
       "      <td>('way', 102)</td>\n",
       "      <td>('philosophy', 88)</td>\n",
       "      <td>('test', 90)</td>\n",
       "      <td>('life', 138)</td>\n",
       "      <td>('power', 102)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Computer Science            Economics            Philosophy  \\\n",
       "0      ('computer', 706)      ('people', 339)        ('thing', 355)   \n",
       "1         ('datum', 281)       ('price', 338)       ('people', 303)   \n",
       "2        ('memory', 259)       ('money', 273)          ('way', 273)   \n",
       "3          ('time', 246)  ('government', 256)         ('time', 248)   \n",
       "4        ('number', 233)     ('economy', 244)        ('world', 233)   \n",
       "5       ('program', 232)   ('economist', 238)         ('life', 214)   \n",
       "6           ('bit', 226)      ('market', 236)       ('belief', 188)   \n",
       "7         ('value', 212)     ('country', 226)     ('argument', 179)   \n",
       "8       ('example', 205)        ('cost', 203)  ('philosopher', 176)   \n",
       "9         ('thing', 173)       ('thing', 142)       ('person', 167)   \n",
       "10      ('machine', 171)      ('income', 138)         ('word', 144)   \n",
       "11         ('code', 167)        ('time', 135)       ('course', 137)   \n",
       "12  ('instruction', 154)      ('worker', 128)         ('idea', 120)   \n",
       "13          ('way', 149)        ('year', 126)      ('episode', 118)   \n",
       "14       ('system', 129)    ('economic', 115)     ('question', 115)   \n",
       "15        ('today', 118)         ('lot', 108)       ('theory', 115)   \n",
       "16         ('line', 112)    ('business', 106)          ('lot', 101)   \n",
       "17       ('people', 111)      ('dollar', 106)         ('view', 100)   \n",
       "18         ('file', 111)      ('supply', 105)          ('case', 97)   \n",
       "19        ('level', 102)         ('way', 102)    ('philosophy', 88)   \n",
       "\n",
       "              Psychology         Sociology     World History  \n",
       "0         ('brain', 268)   ('people', 525)   ('people', 325)  \n",
       "1        ('people', 245)  ('society', 493)  ('history', 273)  \n",
       "2         ('thing', 205)    ('group', 270)     ('week', 207)  \n",
       "3      ('disorder', 203)    ('class', 231)    ('world', 203)  \n",
       "4           ('way', 194)      ('way', 211)     ('time', 200)  \n",
       "5      ('behavior', 190)   ('family', 209)      ('way', 194)  \n",
       "6          ('time', 171)   ('course', 206)      ('war', 194)  \n",
       "7           ('lot', 134)   ('school', 193)    ('today', 175)  \n",
       "8        ('memory', 133)    ('thing', 188)   ('course', 169)  \n",
       "9   ('personality', 111)    ('woman', 186)    ('thing', 155)  \n",
       "10         ('kind', 105)   ('gender', 185)    ('thank', 144)  \n",
       "11        ('group', 103)  ('example', 181)    ('trade', 143)  \n",
       "12       ('episode', 98)   ('theory', 179)      ('lot', 142)  \n",
       "13       ('emotion', 97)   ('system', 175)     ('year', 139)  \n",
       "14          ('mind', 94)     ('time', 162)  ('century', 139)  \n",
       "15        ('person', 94)  ('culture', 160)    ('slave', 122)  \n",
       "16  ('psychologist', 91)   ('income', 159)   ('empire', 120)  \n",
       "17    ('psychology', 90)     ('race', 153)     ('idea', 105)  \n",
       "18          ('life', 90)  ('country', 145)     ('life', 104)  \n",
       "19          ('test', 90)     ('life', 138)    ('power', 102)  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pos_words['NOUN'].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4ec4dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Economics</th>\n",
       "      <th>Philosophy</th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Sociology</th>\n",
       "      <th>World History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('Computer', 53)</td>\n",
       "      <td>('Jacob', 127)</td>\n",
       "      <td>('God', 288)</td>\n",
       "      <td>('Freud', 52)</td>\n",
       "      <td>('Americans', 135)</td>\n",
       "      <td>('Green', 169)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('Anne', 44)</td>\n",
       "      <td>('Adriene', 121)</td>\n",
       "      <td>('Squarespace', 179)</td>\n",
       "      <td>('Crash', 49)</td>\n",
       "      <td>('Crash', 124)</td>\n",
       "      <td>('China', 140)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('Science', 44)</td>\n",
       "      <td>('Crash', 107)</td>\n",
       "      <td>('Crash', 125)</td>\n",
       "      <td>('Dr.', 47)</td>\n",
       "      <td>('Thought', 113)</td>\n",
       "      <td>('Stan', 139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('Register', 39)</td>\n",
       "      <td>('Clifford', 91)</td>\n",
       "      <td>('Thought', 118)</td>\n",
       "      <td>('Yale', 41)</td>\n",
       "      <td>('Marx', 73)</td>\n",
       "      <td>('Thought', 132)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('INTRO', 36)</td>\n",
       "      <td>('Economics', 79)</td>\n",
       "      <td>('Philosophy', 111)</td>\n",
       "      <td>('Michael', 41)</td>\n",
       "      <td>('United', 68)</td>\n",
       "      <td>('World', 120)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('algorithm', 36)</td>\n",
       "      <td>('Thought', 69)</td>\n",
       "      <td>('Course', 96)</td>\n",
       "      <td>('Aranda', 41)</td>\n",
       "      <td>('States', 66)</td>\n",
       "      <td>('Crash', 108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('IBM', 35)</td>\n",
       "      <td>('Mr.', 64)</td>\n",
       "      <td>('PBS', 80)</td>\n",
       "      <td>('Kathleen', 40)</td>\n",
       "      <td>('Patreon', 60)</td>\n",
       "      <td>('Europe', 105)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(['Carrie', 34)</td>\n",
       "      <td>('U.S.', 61)</td>\n",
       "      <td>('Aquinas', 66)</td>\n",
       "      <td>('Blake', 40)</td>\n",
       "      <td>('Weber', 57)</td>\n",
       "      <td>('Bubble', 101)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('RAM', 34)</td>\n",
       "      <td>('GDP', 56)</td>\n",
       "      <td>('Doctor', 53)</td>\n",
       "      <td>('Pastino', 40)</td>\n",
       "      <td>('Durkheim', 52)</td>\n",
       "      <td>('War', 97)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('Crash', 30)</td>\n",
       "      <td>('Course', 54)</td>\n",
       "      <td>('Digital', 46)</td>\n",
       "      <td>('Bhagwat', 40)</td>\n",
       "      <td>('Sociology', 48)</td>\n",
       "      <td>('Mongols', 82)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('Apple', 30)</td>\n",
       "      <td>('Stan', 51)</td>\n",
       "      <td>('Studios', 46)</td>\n",
       "      <td>('Jenkins', 40)</td>\n",
       "      <td>('Dr.', 44)</td>\n",
       "      <td>('Africa', 78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('John', 28)</td>\n",
       "      <td>('United', 47)</td>\n",
       "      <td>('Cheryl', 46)</td>\n",
       "      <td>('Thought', 40)</td>\n",
       "      <td>('Cheryl', 44)</td>\n",
       "      <td>('India', 74)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('File', 28)</td>\n",
       "      <td>('States', 41)</td>\n",
       "      <td>('Kinney', 46)</td>\n",
       "      <td>('Bernice', 40)</td>\n",
       "      <td>('Kinney', 44)</td>\n",
       "      <td>('John', 71)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('Course', 23)</td>\n",
       "      <td>('Patreon', 41)</td>\n",
       "      <td>('Studio', 46)</td>\n",
       "      <td>('Ranjit', 39)</td>\n",
       "      <td>('Studio', 44)</td>\n",
       "      <td>('Mr.', 70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('JUMP', 23)</td>\n",
       "      <td>('Bubble', 40)</td>\n",
       "      <td>('Cafe'], 45)</td>\n",
       "      <td>('Nicholas', 39)</td>\n",
       "      <td>('Missoula', 44)</td>\n",
       "      <td>('Rome', 69)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('Episode', 22)</td>\n",
       "      <td>('Hill', 37)</td>\n",
       "      <td>('Aristotle', 43)</td>\n",
       "      <td>('Subbable', 32)</td>\n",
       "      <td>('Cafe', 44)</td>\n",
       "      <td>('Egypt', 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>('Microsoft', 21)</td>\n",
       "      <td>('China', 31)</td>\n",
       "      <td>('Socrates', 41)</td>\n",
       "      <td>('Skinner', 23)</td>\n",
       "      <td>('Adobe', 44)</td>\n",
       "      <td>('Europeans', 66)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>('System', 21)</td>\n",
       "      <td>('Music', 30)</td>\n",
       "      <td>('Flash', 37)</td>\n",
       "      <td>('Cafe'], 23)</td>\n",
       "      <td>('Creative', 44)</td>\n",
       "      <td>('Revolution', 65)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>('Xerox', 20)</td>\n",
       "      <td>('Fed', 30)</td>\n",
       "      <td>('Bubble', 35)</td>\n",
       "      <td>('Disorder', 22)</td>\n",
       "      <td>('Cloud', 44)</td>\n",
       "      <td>('Empire', 64)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>('ALU', 20)</td>\n",
       "      <td>('Americans', 20)</td>\n",
       "      <td>('Plato', 34)</td>\n",
       "      <td>('Piaget', 20)</td>\n",
       "      <td>('Black', 29)</td>\n",
       "      <td>('French', 63)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Computer Science          Economics            Philosophy  \\\n",
       "0    ('Computer', 53)     ('Jacob', 127)          ('God', 288)   \n",
       "1        ('Anne', 44)   ('Adriene', 121)  ('Squarespace', 179)   \n",
       "2     ('Science', 44)     ('Crash', 107)        ('Crash', 125)   \n",
       "3    ('Register', 39)   ('Clifford', 91)      ('Thought', 118)   \n",
       "4       ('INTRO', 36)  ('Economics', 79)   ('Philosophy', 111)   \n",
       "5   ('algorithm', 36)    ('Thought', 69)        ('Course', 96)   \n",
       "6         ('IBM', 35)        ('Mr.', 64)           ('PBS', 80)   \n",
       "7     (['Carrie', 34)       ('U.S.', 61)       ('Aquinas', 66)   \n",
       "8         ('RAM', 34)        ('GDP', 56)        ('Doctor', 53)   \n",
       "9       ('Crash', 30)     ('Course', 54)       ('Digital', 46)   \n",
       "10      ('Apple', 30)       ('Stan', 51)       ('Studios', 46)   \n",
       "11       ('John', 28)     ('United', 47)        ('Cheryl', 46)   \n",
       "12       ('File', 28)     ('States', 41)        ('Kinney', 46)   \n",
       "13     ('Course', 23)    ('Patreon', 41)        ('Studio', 46)   \n",
       "14       ('JUMP', 23)     ('Bubble', 40)         ('Cafe'], 45)   \n",
       "15    ('Episode', 22)       ('Hill', 37)     ('Aristotle', 43)   \n",
       "16  ('Microsoft', 21)      ('China', 31)      ('Socrates', 41)   \n",
       "17     ('System', 21)      ('Music', 30)         ('Flash', 37)   \n",
       "18      ('Xerox', 20)        ('Fed', 30)        ('Bubble', 35)   \n",
       "19        ('ALU', 20)  ('Americans', 20)         ('Plato', 34)   \n",
       "\n",
       "          Psychology           Sociology       World History  \n",
       "0      ('Freud', 52)  ('Americans', 135)      ('Green', 169)  \n",
       "1      ('Crash', 49)      ('Crash', 124)      ('China', 140)  \n",
       "2        ('Dr.', 47)    ('Thought', 113)       ('Stan', 139)  \n",
       "3       ('Yale', 41)        ('Marx', 73)    ('Thought', 132)  \n",
       "4    ('Michael', 41)      ('United', 68)      ('World', 120)  \n",
       "5     ('Aranda', 41)      ('States', 66)      ('Crash', 108)  \n",
       "6   ('Kathleen', 40)     ('Patreon', 60)     ('Europe', 105)  \n",
       "7      ('Blake', 40)       ('Weber', 57)     ('Bubble', 101)  \n",
       "8    ('Pastino', 40)    ('Durkheim', 52)         ('War', 97)  \n",
       "9    ('Bhagwat', 40)   ('Sociology', 48)     ('Mongols', 82)  \n",
       "10   ('Jenkins', 40)         ('Dr.', 44)      ('Africa', 78)  \n",
       "11   ('Thought', 40)      ('Cheryl', 44)       ('India', 74)  \n",
       "12   ('Bernice', 40)      ('Kinney', 44)        ('John', 71)  \n",
       "13    ('Ranjit', 39)      ('Studio', 44)         ('Mr.', 70)  \n",
       "14  ('Nicholas', 39)    ('Missoula', 44)        ('Rome', 69)  \n",
       "15  ('Subbable', 32)        ('Cafe', 44)       ('Egypt', 67)  \n",
       "16   ('Skinner', 23)       ('Adobe', 44)   ('Europeans', 66)  \n",
       "17     ('Cafe'], 23)    ('Creative', 44)  ('Revolution', 65)  \n",
       "18  ('Disorder', 22)       ('Cloud', 44)      ('Empire', 64)  \n",
       "19    ('Piaget', 20)       ('Black', 29)      ('French', 63)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pos_words['PROPN'].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "316b83af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Economics</th>\n",
       "      <th>Philosophy</th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Sociology</th>\n",
       "      <th>World History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('different', 136)</td>\n",
       "      <td>('high', 185)</td>\n",
       "      <td>('good', 208)</td>\n",
       "      <td>('different', 148)</td>\n",
       "      <td>('social', 479)</td>\n",
       "      <td>('good', 173)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('new', 129)</td>\n",
       "      <td>('economic', 114)</td>\n",
       "      <td>('moral', 141)</td>\n",
       "      <td>('social', 108)</td>\n",
       "      <td>('different', 237)</td>\n",
       "      <td>('great', 119)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('single', 90)</td>\n",
       "      <td>('low', 113)</td>\n",
       "      <td>('right', 97)</td>\n",
       "      <td>('psychological', 95)</td>\n",
       "      <td>('high', 147)</td>\n",
       "      <td>('new', 104)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('small', 89)</td>\n",
       "      <td>('good', 105)</td>\n",
       "      <td>('true', 94)</td>\n",
       "      <td>('good', 81)</td>\n",
       "      <td>('likely', 119)</td>\n",
       "      <td>('important', 86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('big', 86)</td>\n",
       "      <td>('free', 90)</td>\n",
       "      <td>('different', 84)</td>\n",
       "      <td>('new', 79)</td>\n",
       "      <td>('economic', 106)</td>\n",
       "      <td>('british', 78)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('simple', 79)</td>\n",
       "      <td>('bad', 67)</td>\n",
       "      <td>('wrong', 79)</td>\n",
       "      <td>('mental', 79)</td>\n",
       "      <td>('low', 103)</td>\n",
       "      <td>('high', 70)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('early', 77)</td>\n",
       "      <td>('new', 65)</td>\n",
       "      <td>('free', 73)</td>\n",
       "      <td>('little', 67)</td>\n",
       "      <td>('cultural', 99)</td>\n",
       "      <td>('big', 63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('human', 74)</td>\n",
       "      <td>('different', 60)</td>\n",
       "      <td>('human', 68)</td>\n",
       "      <td>('big', 65)</td>\n",
       "      <td>('political', 91)</td>\n",
       "      <td>('european', 63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('little', 74)</td>\n",
       "      <td>('big', 60)</td>\n",
       "      <td>('real', 67)</td>\n",
       "      <td>('important', 64)</td>\n",
       "      <td>('good', 85)</td>\n",
       "      <td>('bad', 56)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('true', 65)</td>\n",
       "      <td>('great', 58)</td>\n",
       "      <td>('possible', 63)</td>\n",
       "      <td>('cognitive', 54)</td>\n",
       "      <td>('american', 84)</td>\n",
       "      <td>('human', 52)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('high', 62)</td>\n",
       "      <td>('financial', 58)</td>\n",
       "      <td>('bad', 62)</td>\n",
       "      <td>('old', 53)</td>\n",
       "      <td>('white', 83)</td>\n",
       "      <td>('rich', 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('possible', 61)</td>\n",
       "      <td>('well', 56)</td>\n",
       "      <td>('new', 58)</td>\n",
       "      <td>('long', 48)</td>\n",
       "      <td>('important', 82)</td>\n",
       "      <td>('roman', 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('good', 59)</td>\n",
       "      <td>('poor', 51)</td>\n",
       "      <td>('great', 55)</td>\n",
       "      <td>('certain', 48)</td>\n",
       "      <td>('racial', 76)</td>\n",
       "      <td>('well', 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('huge', 58)</td>\n",
       "      <td>('large', 47)</td>\n",
       "      <td>('awesome', 52)</td>\n",
       "      <td>('human', 46)</td>\n",
       "      <td>('black', 71)</td>\n",
       "      <td>('large', 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('useful', 56)</td>\n",
       "      <td>('marginal', 47)</td>\n",
       "      <td>('physical', 50)</td>\n",
       "      <td>('high', 46)</td>\n",
       "      <td>('big', 57)</td>\n",
       "      <td>('american', 47)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('low', 54)</td>\n",
       "      <td>('additional', 46)</td>\n",
       "      <td>('hard', 49)</td>\n",
       "      <td>('sexual', 46)</td>\n",
       "      <td>('free', 57)</td>\n",
       "      <td>('easy', 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>('large', 53)</td>\n",
       "      <td>('public', 45)</td>\n",
       "      <td>('little', 47)</td>\n",
       "      <td>('right', 43)</td>\n",
       "      <td>('common', 56)</td>\n",
       "      <td>('long', 46)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>('easy', 45)</td>\n",
       "      <td>('rich', 45)</td>\n",
       "      <td>('well', 47)</td>\n",
       "      <td>('hard', 41)</td>\n",
       "      <td>('structural', 56)</td>\n",
       "      <td>('different', 45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>('able', 44)</td>\n",
       "      <td>('small', 44)</td>\n",
       "      <td>('particular', 47)</td>\n",
       "      <td>('bad', 38)</td>\n",
       "      <td>('new', 52)</td>\n",
       "      <td>('political', 44)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>('right', 43)</td>\n",
       "      <td>('real', 42)</td>\n",
       "      <td>('false', 45)</td>\n",
       "      <td>('biological', 37)</td>\n",
       "      <td>('large', 51)</td>\n",
       "      <td>('possible', 44)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Computer Science           Economics          Philosophy  \\\n",
       "0   ('different', 136)       ('high', 185)       ('good', 208)   \n",
       "1         ('new', 129)   ('economic', 114)      ('moral', 141)   \n",
       "2       ('single', 90)        ('low', 113)       ('right', 97)   \n",
       "3        ('small', 89)       ('good', 105)        ('true', 94)   \n",
       "4          ('big', 86)        ('free', 90)   ('different', 84)   \n",
       "5       ('simple', 79)         ('bad', 67)       ('wrong', 79)   \n",
       "6        ('early', 77)         ('new', 65)        ('free', 73)   \n",
       "7        ('human', 74)   ('different', 60)       ('human', 68)   \n",
       "8       ('little', 74)         ('big', 60)        ('real', 67)   \n",
       "9         ('true', 65)       ('great', 58)    ('possible', 63)   \n",
       "10        ('high', 62)   ('financial', 58)         ('bad', 62)   \n",
       "11    ('possible', 61)        ('well', 56)         ('new', 58)   \n",
       "12        ('good', 59)        ('poor', 51)       ('great', 55)   \n",
       "13        ('huge', 58)       ('large', 47)     ('awesome', 52)   \n",
       "14      ('useful', 56)    ('marginal', 47)    ('physical', 50)   \n",
       "15         ('low', 54)  ('additional', 46)        ('hard', 49)   \n",
       "16       ('large', 53)      ('public', 45)      ('little', 47)   \n",
       "17        ('easy', 45)        ('rich', 45)        ('well', 47)   \n",
       "18        ('able', 44)       ('small', 44)  ('particular', 47)   \n",
       "19       ('right', 43)        ('real', 42)       ('false', 45)   \n",
       "\n",
       "               Psychology           Sociology      World History  \n",
       "0      ('different', 148)     ('social', 479)      ('good', 173)  \n",
       "1         ('social', 108)  ('different', 237)     ('great', 119)  \n",
       "2   ('psychological', 95)       ('high', 147)       ('new', 104)  \n",
       "3            ('good', 81)     ('likely', 119)  ('important', 86)  \n",
       "4             ('new', 79)   ('economic', 106)    ('british', 78)  \n",
       "5          ('mental', 79)        ('low', 103)       ('high', 70)  \n",
       "6          ('little', 67)    ('cultural', 99)        ('big', 63)  \n",
       "7             ('big', 65)   ('political', 91)   ('european', 63)  \n",
       "8       ('important', 64)        ('good', 85)        ('bad', 56)  \n",
       "9       ('cognitive', 54)    ('american', 84)      ('human', 52)  \n",
       "10            ('old', 53)       ('white', 83)       ('rich', 49)  \n",
       "11           ('long', 48)   ('important', 82)      ('roman', 49)  \n",
       "12        ('certain', 48)      ('racial', 76)       ('well', 47)  \n",
       "13          ('human', 46)       ('black', 71)      ('large', 47)  \n",
       "14           ('high', 46)         ('big', 57)   ('american', 47)  \n",
       "15         ('sexual', 46)        ('free', 57)       ('easy', 46)  \n",
       "16          ('right', 43)      ('common', 56)       ('long', 46)  \n",
       "17           ('hard', 41)  ('structural', 56)  ('different', 45)  \n",
       "18            ('bad', 38)         ('new', 52)  ('political', 44)  \n",
       "19     ('biological', 37)       ('large', 51)   ('possible', 44)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pos_words['ADJ'].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1021401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Economics</th>\n",
       "      <th>Philosophy</th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Sociology</th>\n",
       "      <th>World History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('instead', 82)</td>\n",
       "      <td>('actually', 70)</td>\n",
       "      <td>('actually', 138)</td>\n",
       "      <td>('actually', 104)</td>\n",
       "      <td>('finally', 46)</td>\n",
       "      <td>('probably', 79)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('pretty', 62)</td>\n",
       "      <td>('pretty', 42)</td>\n",
       "      <td>('probably', 81)</td>\n",
       "      <td>('probably', 68)</td>\n",
       "      <td>('instead', 46)</td>\n",
       "      <td>('especially', 68)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('fast', 39)</td>\n",
       "      <td>('basically', 35)</td>\n",
       "      <td>('pretty', 63)</td>\n",
       "      <td>('pretty', 59)</td>\n",
       "      <td>('pretty', 46)</td>\n",
       "      <td>('pretty', 64)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('finally', 38)</td>\n",
       "      <td>('instead', 34)</td>\n",
       "      <td>('maybe', 62)</td>\n",
       "      <td>('maybe', 46)</td>\n",
       "      <td>('probably', 36)</td>\n",
       "      <td>('actually', 59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('later', 36)</td>\n",
       "      <td>('forever'], 31)</td>\n",
       "      <td>('simply', 59)</td>\n",
       "      <td>('instead', 37)</td>\n",
       "      <td>('actually', 35)</td>\n",
       "      <td>('eventually', 49)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('roughly', 34)</td>\n",
       "      <td>('probably', 26)</td>\n",
       "      <td>('instead', 52)</td>\n",
       "      <td>('basically', 34)</td>\n",
       "      <td>('forever'], 28)</td>\n",
       "      <td>('basically', 39)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('right', 32)</td>\n",
       "      <td>('well', 25)</td>\n",
       "      <td>('equally'], 40)</td>\n",
       "      <td>('especially'], 33)</td>\n",
       "      <td>('far', 26)</td>\n",
       "      <td>('long', 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('long', 29)</td>\n",
       "      <td>('relatively', 24)</td>\n",
       "      <td>('basically', 37)</td>\n",
       "      <td>('simply', 32)</td>\n",
       "      <td>('basically', 25)</td>\n",
       "      <td>('far', 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('probably', 28)</td>\n",
       "      <td>('eventually', 23)</td>\n",
       "      <td>('morally', 36)</td>\n",
       "      <td>('right', 32)</td>\n",
       "      <td>('long', 25)</td>\n",
       "      <td>('instead', 32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('course', 27)</td>\n",
       "      <td>('maybe', 21)</td>\n",
       "      <td>('long', 35)</td>\n",
       "      <td>('usually', 30)</td>\n",
       "      <td>('typically', 23)</td>\n",
       "      <td>('usually', 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('actually', 24)</td>\n",
       "      <td>('right', 20)</td>\n",
       "      <td>('right', 33)</td>\n",
       "      <td>('well', 28)</td>\n",
       "      <td>('especially', 22)</td>\n",
       "      <td>('later', 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('soon', 24)</td>\n",
       "      <td>('quickly', 20)</td>\n",
       "      <td>('far', 30)</td>\n",
       "      <td>('eventually', 27)</td>\n",
       "      <td>('simply', 22)</td>\n",
       "      <td>('right', 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('inside', 24)</td>\n",
       "      <td>('exactly', 19)</td>\n",
       "      <td>('away', 26)</td>\n",
       "      <td>('finally', 25)</td>\n",
       "      <td>('maybe', 21)</td>\n",
       "      <td>('maybe', 27)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('maybe', 24)</td>\n",
       "      <td>('long', 17)</td>\n",
       "      <td>('totally', 22)</td>\n",
       "      <td>('long', 25)</td>\n",
       "      <td>('socially', 21)</td>\n",
       "      <td>('soon', 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('far', 21)</td>\n",
       "      <td>('nearly', 16)</td>\n",
       "      <td>('literally', 22)</td>\n",
       "      <td>('away', 24)</td>\n",
       "      <td>('ago', 20)</td>\n",
       "      <td>('primarily', 23)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('easily', 20)</td>\n",
       "      <td>('ago', 15)</td>\n",
       "      <td>('likewise', 19)</td>\n",
       "      <td>('especially', 24)</td>\n",
       "      <td>('usually', 20)</td>\n",
       "      <td>('particularly', 21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>('exactly', 20)</td>\n",
       "      <td>('completely', 14)</td>\n",
       "      <td>('regardless', 19)</td>\n",
       "      <td>('suddenly', 23)</td>\n",
       "      <td>('particularly', 20)</td>\n",
       "      <td>('kind', 21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>('literally', 19)</td>\n",
       "      <td>('away', 13)</td>\n",
       "      <td>('exactly', 18)</td>\n",
       "      <td>('exactly', 22)</td>\n",
       "      <td>('forever', 18)</td>\n",
       "      <td>('away', 21)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>('simply', 19)</td>\n",
       "      <td>('fast', 13)</td>\n",
       "      <td>('finally', 17)</td>\n",
       "      <td>('far', 21)</td>\n",
       "      <td>('differently', 18)</td>\n",
       "      <td>('completely', 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>('away', 19)</td>\n",
       "      <td>('far', 13)</td>\n",
       "      <td>('kind', 17)</td>\n",
       "      <td>('later', 20)</td>\n",
       "      <td>('well', 18)</td>\n",
       "      <td>('finally', 19)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Computer Science           Economics          Philosophy  \\\n",
       "0     ('instead', 82)    ('actually', 70)   ('actually', 138)   \n",
       "1      ('pretty', 62)      ('pretty', 42)    ('probably', 81)   \n",
       "2        ('fast', 39)   ('basically', 35)      ('pretty', 63)   \n",
       "3     ('finally', 38)     ('instead', 34)       ('maybe', 62)   \n",
       "4       ('later', 36)    ('forever'], 31)      ('simply', 59)   \n",
       "5     ('roughly', 34)    ('probably', 26)     ('instead', 52)   \n",
       "6       ('right', 32)        ('well', 25)    ('equally'], 40)   \n",
       "7        ('long', 29)  ('relatively', 24)   ('basically', 37)   \n",
       "8    ('probably', 28)  ('eventually', 23)     ('morally', 36)   \n",
       "9      ('course', 27)       ('maybe', 21)        ('long', 35)   \n",
       "10   ('actually', 24)       ('right', 20)       ('right', 33)   \n",
       "11       ('soon', 24)     ('quickly', 20)         ('far', 30)   \n",
       "12     ('inside', 24)     ('exactly', 19)        ('away', 26)   \n",
       "13      ('maybe', 24)        ('long', 17)     ('totally', 22)   \n",
       "14        ('far', 21)      ('nearly', 16)   ('literally', 22)   \n",
       "15     ('easily', 20)         ('ago', 15)    ('likewise', 19)   \n",
       "16    ('exactly', 20)  ('completely', 14)  ('regardless', 19)   \n",
       "17  ('literally', 19)        ('away', 13)     ('exactly', 18)   \n",
       "18     ('simply', 19)        ('fast', 13)     ('finally', 17)   \n",
       "19       ('away', 19)         ('far', 13)        ('kind', 17)   \n",
       "\n",
       "             Psychology             Sociology         World History  \n",
       "0     ('actually', 104)       ('finally', 46)      ('probably', 79)  \n",
       "1      ('probably', 68)       ('instead', 46)    ('especially', 68)  \n",
       "2        ('pretty', 59)        ('pretty', 46)        ('pretty', 64)  \n",
       "3         ('maybe', 46)      ('probably', 36)      ('actually', 59)  \n",
       "4       ('instead', 37)      ('actually', 35)    ('eventually', 49)  \n",
       "5     ('basically', 34)      ('forever'], 28)     ('basically', 39)  \n",
       "6   ('especially'], 33)           ('far', 26)          ('long', 37)  \n",
       "7        ('simply', 32)     ('basically', 25)           ('far', 32)  \n",
       "8         ('right', 32)          ('long', 25)       ('instead', 32)  \n",
       "9       ('usually', 30)     ('typically', 23)       ('usually', 30)  \n",
       "10         ('well', 28)    ('especially', 22)         ('later', 30)  \n",
       "11   ('eventually', 27)        ('simply', 22)         ('right', 27)  \n",
       "12      ('finally', 25)         ('maybe', 21)         ('maybe', 27)  \n",
       "13         ('long', 25)      ('socially', 21)          ('soon', 23)  \n",
       "14         ('away', 24)           ('ago', 20)     ('primarily', 23)  \n",
       "15   ('especially', 24)       ('usually', 20)  ('particularly', 21)  \n",
       "16     ('suddenly', 23)  ('particularly', 20)          ('kind', 21)  \n",
       "17      ('exactly', 22)       ('forever', 18)          ('away', 21)  \n",
       "18          ('far', 21)   ('differently', 18)    ('completely', 20)  \n",
       "19        ('later', 20)          ('well', 18)       ('finally', 19)  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pos_words['ADV'].head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1065277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Economics</th>\n",
       "      <th>Philosophy</th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Sociology</th>\n",
       "      <th>World History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('call', 293)</td>\n",
       "      <td>('produce', 175)</td>\n",
       "      <td>('think', 411)</td>\n",
       "      <td>('think', 180)</td>\n",
       "      <td>('think', 162)</td>\n",
       "      <td>('know', 214)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('need', 185)</td>\n",
       "      <td>('pay', 171)</td>\n",
       "      <td>('know', 377)</td>\n",
       "      <td>('know', 169)</td>\n",
       "      <td>('talk', 162)</td>\n",
       "      <td>('mean', 195)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('use', 182)</td>\n",
       "      <td>('want', 164)</td>\n",
       "      <td>('say', 268)</td>\n",
       "      <td>('learn', 146)</td>\n",
       "      <td>('look', 151)</td>\n",
       "      <td>('go', 153)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('let', 172)</td>\n",
       "      <td>('go', 150)</td>\n",
       "      <td>('mean', 215)</td>\n",
       "      <td>('help', 120)</td>\n",
       "      <td>('work', 151)</td>\n",
       "      <td>('let', 149)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('know', 168)</td>\n",
       "      <td>('buy', 149)</td>\n",
       "      <td>('go', 176)</td>\n",
       "      <td>('feel', 119)</td>\n",
       "      <td>('understand', 137)</td>\n",
       "      <td>('call', 147)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>('go', 166)</td>\n",
       "      <td>('let', 146)</td>\n",
       "      <td>('believe', 163)</td>\n",
       "      <td>('call', 118)</td>\n",
       "      <td>('mean', 136)</td>\n",
       "      <td>('want', 134)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>('store', 156)</td>\n",
       "      <td>('help', 140)</td>\n",
       "      <td>('talk', 151)</td>\n",
       "      <td>('come', 114)</td>\n",
       "      <td>('know', 135)</td>\n",
       "      <td>('come', 131)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>('want', 141)</td>\n",
       "      <td>('call', 125)</td>\n",
       "      <td>('come', 134)</td>\n",
       "      <td>('mean', 104)</td>\n",
       "      <td>('live', 119)</td>\n",
       "      <td>('think', 112)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>('run', 127)</td>\n",
       "      <td>('look', 107)</td>\n",
       "      <td>('want', 131)</td>\n",
       "      <td>('look', 104)</td>\n",
       "      <td>('come', 119)</td>\n",
       "      <td>('live', 107)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>('write', 126)</td>\n",
       "      <td>('increase', 106)</td>\n",
       "      <td>('argue', 113)</td>\n",
       "      <td>('talk', 98)</td>\n",
       "      <td>('help', 111)</td>\n",
       "      <td>('lead', 106)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>('start', 120)</td>\n",
       "      <td>('need', 103)</td>\n",
       "      <td>('let', 107)</td>\n",
       "      <td>('get', 91)</td>\n",
       "      <td>('see', 104)</td>\n",
       "      <td>('talk', 105)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>('add', 115)</td>\n",
       "      <td>('mean', 98)</td>\n",
       "      <td>('need', 104)</td>\n",
       "      <td>('understand', 89)</td>\n",
       "      <td>('support', 100)</td>\n",
       "      <td>('write', 98)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>('work', 112)</td>\n",
       "      <td>('make', 96)</td>\n",
       "      <td>('look', 100)</td>\n",
       "      <td>('work', 88)</td>\n",
       "      <td>('like', 93)</td>\n",
       "      <td>('watch', 87)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>('look', 111)</td>\n",
       "      <td>('get', 91)</td>\n",
       "      <td>('exist', 100)</td>\n",
       "      <td>('go', 84)</td>\n",
       "      <td>('tend', 92)</td>\n",
       "      <td>('take', 86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>('build', 108)</td>\n",
       "      <td>('watch', 90)</td>\n",
       "      <td>('help', 95)</td>\n",
       "      <td>('start', 84)</td>\n",
       "      <td>('learn', 90)</td>\n",
       "      <td>('see', 86)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>('get', 107)</td>\n",
       "      <td>('talk', 87)</td>\n",
       "      <td>('happen', 93)</td>\n",
       "      <td>('find', 84)</td>\n",
       "      <td>('make', 85)</td>\n",
       "      <td>('look', 84)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>('talk', 93)</td>\n",
       "      <td>('going', 78)</td>\n",
       "      <td>('make', 92)</td>\n",
       "      <td>('watch', 76)</td>\n",
       "      <td>('need', 83)</td>\n",
       "      <td>('try', 84)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>('mean', 91)</td>\n",
       "      <td>('spend', 78)</td>\n",
       "      <td>('find', 92)</td>\n",
       "      <td>('give', 67)</td>\n",
       "      <td>('base', 83)</td>\n",
       "      <td>('work', 75)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>('create', 89)</td>\n",
       "      <td>('think', 76)</td>\n",
       "      <td>('try', 89)</td>\n",
       "      <td>('tell', 67)</td>\n",
       "      <td>('call', 82)</td>\n",
       "      <td>('make', 73)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>('allow', 85)</td>\n",
       "      <td>('start', 73)</td>\n",
       "      <td>('create', 88)</td>\n",
       "      <td>('remember', 63)</td>\n",
       "      <td>('allow', 81)</td>\n",
       "      <td>('say', 72)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Computer Science          Economics        Philosophy          Psychology  \\\n",
       "0     ('call', 293)   ('produce', 175)    ('think', 411)      ('think', 180)   \n",
       "1     ('need', 185)       ('pay', 171)     ('know', 377)       ('know', 169)   \n",
       "2      ('use', 182)      ('want', 164)      ('say', 268)      ('learn', 146)   \n",
       "3      ('let', 172)        ('go', 150)     ('mean', 215)       ('help', 120)   \n",
       "4     ('know', 168)       ('buy', 149)       ('go', 176)       ('feel', 119)   \n",
       "5       ('go', 166)       ('let', 146)  ('believe', 163)       ('call', 118)   \n",
       "6    ('store', 156)      ('help', 140)     ('talk', 151)       ('come', 114)   \n",
       "7     ('want', 141)      ('call', 125)     ('come', 134)       ('mean', 104)   \n",
       "8      ('run', 127)      ('look', 107)     ('want', 131)       ('look', 104)   \n",
       "9    ('write', 126)  ('increase', 106)    ('argue', 113)        ('talk', 98)   \n",
       "10   ('start', 120)      ('need', 103)      ('let', 107)         ('get', 91)   \n",
       "11     ('add', 115)       ('mean', 98)     ('need', 104)  ('understand', 89)   \n",
       "12    ('work', 112)       ('make', 96)     ('look', 100)        ('work', 88)   \n",
       "13    ('look', 111)        ('get', 91)    ('exist', 100)          ('go', 84)   \n",
       "14   ('build', 108)      ('watch', 90)      ('help', 95)       ('start', 84)   \n",
       "15     ('get', 107)       ('talk', 87)    ('happen', 93)        ('find', 84)   \n",
       "16     ('talk', 93)      ('going', 78)      ('make', 92)       ('watch', 76)   \n",
       "17     ('mean', 91)      ('spend', 78)      ('find', 92)        ('give', 67)   \n",
       "18   ('create', 89)      ('think', 76)       ('try', 89)        ('tell', 67)   \n",
       "19    ('allow', 85)      ('start', 73)    ('create', 88)    ('remember', 63)   \n",
       "\n",
       "              Sociology   World History  \n",
       "0        ('think', 162)   ('know', 214)  \n",
       "1         ('talk', 162)   ('mean', 195)  \n",
       "2         ('look', 151)     ('go', 153)  \n",
       "3         ('work', 151)    ('let', 149)  \n",
       "4   ('understand', 137)   ('call', 147)  \n",
       "5         ('mean', 136)   ('want', 134)  \n",
       "6         ('know', 135)   ('come', 131)  \n",
       "7         ('live', 119)  ('think', 112)  \n",
       "8         ('come', 119)   ('live', 107)  \n",
       "9         ('help', 111)   ('lead', 106)  \n",
       "10         ('see', 104)   ('talk', 105)  \n",
       "11     ('support', 100)   ('write', 98)  \n",
       "12         ('like', 93)   ('watch', 87)  \n",
       "13         ('tend', 92)    ('take', 86)  \n",
       "14        ('learn', 90)     ('see', 86)  \n",
       "15         ('make', 85)    ('look', 84)  \n",
       "16         ('need', 83)     ('try', 84)  \n",
       "17         ('base', 83)    ('work', 75)  \n",
       "18         ('call', 82)    ('make', 73)  \n",
       "19        ('allow', 81)     ('say', 72)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_pos_words['VERB'].head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44da33e",
   "metadata": {},
   "source": [
    "<h1>\n",
    "<div style ='direction: rtl; font-family: \"B Nazanin\";'>\n",
    "    بخش ۸. استخراج کلمات کلیدی با استفاده از Yake\n",
    "    </div>\n",
    "    </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1716e53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/LIAAD/yake\n",
      "  Cloning https://github.com/LIAAD/yake to c:\\users\\amirreza\\appdata\\local\\temp\\pip-req-build-b8otvoyb\n",
      "  Resolved https://github.com/LIAAD/yake to commit 238ae58c5ba39326a96862ee0e9cb817e5958440\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tabulate in c:\\python38\\lib\\site-packages (from yake==0.4.8) (0.8.9)\n",
      "Requirement already satisfied: click>=6.0 in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from yake==0.4.8) (8.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from yake==0.4.8) (1.21.0)\n",
      "Requirement already satisfied: segtok in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from yake==0.4.8) (1.5.11)\n",
      "Requirement already satisfied: networkx in c:\\python38\\lib\\site-packages (from yake==0.4.8) (2.8)\n",
      "Requirement already satisfied: jellyfish in c:\\users\\amirreza\\appdata\\roaming\\python\\python38\\site-packages (from yake==0.4.8) (0.9.0)\n",
      "Requirement already satisfied: colorama in c:\\python38\\lib\\site-packages (from click>=6.0->yake==0.4.8) (0.3.9)\n",
      "Requirement already satisfied: regex in c:\\python38\\lib\\site-packages (from segtok->yake==0.4.8) (2022.3.15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/LIAAD/yake 'C:\\Users\\Amirreza\\AppData\\Local\\Temp\\pip-req-build-b8otvoyb'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/LIAAD/yake --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd057774",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; font-family: B Nazanin; font-size: 18px;\">\n",
    "کلمات کلیدی متن‌های تجمیع شده براساس موضوع، به ترتیب اهمیتشان با استفاده از تابع get_keywords استخراج و در دیتافریم keywords ذخیره شد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea245564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yake\n",
    "\n",
    "def get_keywords(text, top=50):\n",
    "    keyword_extractor = yake.KeywordExtractor(top=top)\n",
    "    keywords = keyword_extractor.extract_keywords(text)\n",
    "    return [keyword[0] for keyword in keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a047b5eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Computer Science</th>\n",
       "      <td>[Hello world! I’m Carrie Anne Philbin and welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>[Today, we peer into a world where shadowy gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philosophy</th>\n",
       "      <td>[I’ve got a new set! With new props like my fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psychology</th>\n",
       "      <td>[Hello, and welcome to my new set! I'm on a ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sociology</th>\n",
       "      <td>[Hello! I am not Hank. I am Nicole and I’m usu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Text\n",
       "Subject                                                            \n",
       "Computer Science  [Hello world! I’m Carrie Anne Philbin and welc...\n",
       "Economics         [Today, we peer into a world where shadowy gov...\n",
       "Philosophy        [I’ve got a new set! With new props like my fr...\n",
       "Psychology        [Hello, and welcome to my new set! I'm on a ch...\n",
       "Sociology         [Hello! I am not Hank. I am Nicole and I’m usu..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_words = df.groupby(\"Subject\")['Text'].apply(list)\n",
    "subject_words = pd.DataFrame(subject_words)\n",
    "subject_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc186e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World History</th>\n",
       "      <th>Economics</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Philosophy</th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Sociology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thought Bubble</td>\n",
       "      <td>Thought Bubble</td>\n",
       "      <td>Computer</td>\n",
       "      <td>PBS digital studios</td>\n",
       "      <td>people</td>\n",
       "      <td>Adobe Creative Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Green</td>\n",
       "      <td>people</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>n’t</td>\n",
       "      <td>brain</td>\n",
       "      <td>Thought Bubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>World History</td>\n",
       "      <td>Economics</td>\n",
       "      <td>computers</td>\n",
       "      <td>Thought Bubble</td>\n",
       "      <td>Michael Aranda</td>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World War</td>\n",
       "      <td>Crash Course Economics</td>\n",
       "      <td>CrashCourse Computer Science</td>\n",
       "      <td>Crash Course Philosophy</td>\n",
       "      <td>Kathleen Yale</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World</td>\n",
       "      <td>Jacob Clifford Adriene</td>\n",
       "      <td>data</td>\n",
       "      <td>God</td>\n",
       "      <td>Blake de Pastino</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indian Ocean trade</td>\n",
       "      <td>Crash</td>\n",
       "      <td>computer memory</td>\n",
       "      <td>Kinney Crash</td>\n",
       "      <td>Nicholas Jenkins</td>\n",
       "      <td>Thought Cafe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>history teacher Raoul</td>\n",
       "      <td>Adriene Hill Jacob</td>\n",
       "      <td>memory</td>\n",
       "      <td>Thought Cafe</td>\n",
       "      <td>Ranjit Bhagwat</td>\n",
       "      <td>Black Americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Open Letter</td>\n",
       "      <td>Jacob Clifford</td>\n",
       "      <td>called</td>\n",
       "      <td>’re</td>\n",
       "      <td>disorders</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Roman Empire</td>\n",
       "      <td>Adriene Hill</td>\n",
       "      <td>n’t</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>disorder</td>\n",
       "      <td>Americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>war</td>\n",
       "      <td>Adriene</td>\n",
       "      <td>Carrie Anne</td>\n",
       "      <td>digital studios</td>\n",
       "      <td>Personality Disorder</td>\n",
       "      <td>Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n’t</td>\n",
       "      <td>money</td>\n",
       "      <td>computer systems</td>\n",
       "      <td>Flash Philosophy</td>\n",
       "      <td>behavior</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>History</td>\n",
       "      <td>United States</td>\n",
       "      <td>program</td>\n",
       "      <td>thought</td>\n",
       "      <td>things</td>\n",
       "      <td>White Americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stan Muller</td>\n",
       "      <td>economic</td>\n",
       "      <td>time</td>\n",
       "      <td>Crash</td>\n",
       "      <td>time</td>\n",
       "      <td>Thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Green</td>\n",
       "      <td>price</td>\n",
       "      <td>’re</td>\n",
       "      <td>PBS digital</td>\n",
       "      <td>Thought Cafe</td>\n",
       "      <td>n’t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>people</td>\n",
       "      <td>government</td>\n",
       "      <td>CPU</td>\n",
       "      <td>Crash Course Studio</td>\n",
       "      <td>thought</td>\n",
       "      <td>Theme Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>high school history</td>\n",
       "      <td>economists</td>\n",
       "      <td>computer programs</td>\n",
       "      <td>Aquinas thought God</td>\n",
       "      <td>psychological disorders</td>\n",
       "      <td>Adobe Creative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Thought</td>\n",
       "      <td>prices</td>\n",
       "      <td>number</td>\n",
       "      <td>Squarespace</td>\n",
       "      <td>make Crash</td>\n",
       "      <td>Studio in Missoula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>teacher Raoul Meyer</td>\n",
       "      <td>Jacob</td>\n",
       "      <td>code</td>\n",
       "      <td>Doctor Cheryl</td>\n",
       "      <td>Antisocial Personality Disorder</td>\n",
       "      <td>Cheryl C. Kinney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>American Revolution</td>\n",
       "      <td>Theme Music</td>\n",
       "      <td>machine</td>\n",
       "      <td>people</td>\n",
       "      <td>make</td>\n",
       "      <td>Creative Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>school history teacher</td>\n",
       "      <td>economy</td>\n",
       "      <td>called computer files</td>\n",
       "      <td>Cheryl C. Kinney</td>\n",
       "      <td>lot</td>\n",
       "      <td>Kinney Studio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Crash</td>\n",
       "      <td>Clifford</td>\n",
       "      <td>system</td>\n",
       "      <td>Theme Music</td>\n",
       "      <td>edited by Blake</td>\n",
       "      <td>sociology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>China</td>\n",
       "      <td>GDP</td>\n",
       "      <td>episode</td>\n",
       "      <td>time</td>\n",
       "      <td>personality</td>\n",
       "      <td>Crash Course Sociology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bubble</td>\n",
       "      <td>make</td>\n",
       "      <td>operating system</td>\n",
       "      <td>things</td>\n",
       "      <td>written by Kathleen</td>\n",
       "      <td>African Americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>French Revolution</td>\n",
       "      <td>watching Crash</td>\n",
       "      <td>programs</td>\n",
       "      <td>world</td>\n",
       "      <td>’re</td>\n",
       "      <td>social class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Indian Ocean</td>\n",
       "      <td>market</td>\n",
       "      <td>numbers</td>\n",
       "      <td>PBS Space Time</td>\n",
       "      <td>n’t</td>\n",
       "      <td>American society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stan</td>\n",
       "      <td>n’t</td>\n",
       "      <td>things</td>\n",
       "      <td>thing</td>\n",
       "      <td>Freud</td>\n",
       "      <td>social conflict theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>week</td>\n",
       "      <td>Thought</td>\n",
       "      <td>instruction address register</td>\n",
       "      <td>good</td>\n",
       "      <td>thing</td>\n",
       "      <td>’re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Latin America</td>\n",
       "      <td>Bubble</td>\n",
       "      <td>Systems</td>\n",
       "      <td>PBS Idea Channel</td>\n",
       "      <td>psychology</td>\n",
       "      <td>social world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Raoul Meyer</td>\n",
       "      <td>money supply</td>\n",
       "      <td>computer scientists</td>\n",
       "      <td>n’t make</td>\n",
       "      <td>editor is Nicholas</td>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Empire</td>\n",
       "      <td>economic thought</td>\n",
       "      <td>Science</td>\n",
       "      <td>PBS</td>\n",
       "      <td>Subbable subscribers</td>\n",
       "      <td>Crash Course free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>secret compartment today</td>\n",
       "      <td>cost</td>\n",
       "      <td>file</td>\n",
       "      <td>make</td>\n",
       "      <td>Crash</td>\n",
       "      <td>making Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Danica Johnson</td>\n",
       "      <td>make Crash</td>\n",
       "      <td>CrashCourse Computer</td>\n",
       "      <td>episode of Crash</td>\n",
       "      <td>kind</td>\n",
       "      <td>White Americans tend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>British</td>\n",
       "      <td>costs</td>\n",
       "      <td>Turing Machine</td>\n",
       "      <td>person</td>\n",
       "      <td>psychological</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Eastern Roman Empire</td>\n",
       "      <td>Thought Bubble Jacob</td>\n",
       "      <td>bits</td>\n",
       "      <td>life</td>\n",
       "      <td>work</td>\n",
       "      <td>Cafe and Crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>John Green King</td>\n",
       "      <td>countries</td>\n",
       "      <td>’ve</td>\n",
       "      <td>Bubble</td>\n",
       "      <td>social</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>John</td>\n",
       "      <td>Crash Course free</td>\n",
       "      <td>computing</td>\n",
       "      <td>American philosopher</td>\n",
       "      <td>called</td>\n",
       "      <td>social stratification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Europe</td>\n",
       "      <td>world</td>\n",
       "      <td>RAM</td>\n",
       "      <td>Philosophy is produced</td>\n",
       "      <td>American psychologist</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Years War</td>\n",
       "      <td>markets</td>\n",
       "      <td>today</td>\n",
       "      <td>moral</td>\n",
       "      <td>episode</td>\n",
       "      <td>nice people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>British East India</td>\n",
       "      <td>time</td>\n",
       "      <td>register</td>\n",
       "      <td>Contemporary American philosopher</td>\n",
       "      <td>person</td>\n",
       "      <td>groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Holy Roman Empire</td>\n",
       "      <td>called</td>\n",
       "      <td>instruction</td>\n",
       "      <td>Aquinas thought</td>\n",
       "      <td>sound designer</td>\n",
       "      <td>work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Thought Bubble today</td>\n",
       "      <td>pay</td>\n",
       "      <td>files</td>\n",
       "      <td>argument</td>\n",
       "      <td>group</td>\n",
       "      <td>theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>great</td>\n",
       "      <td>income</td>\n",
       "      <td>times</td>\n",
       "      <td>studios</td>\n",
       "      <td>sound</td>\n",
       "      <td>class Americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>school history</td>\n",
       "      <td>things</td>\n",
       "      <td>File System</td>\n",
       "      <td>Studio</td>\n",
       "      <td>sense</td>\n",
       "      <td>gender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Western Roman Empire</td>\n",
       "      <td>workers</td>\n",
       "      <td>people</td>\n",
       "      <td>n’t exist</td>\n",
       "      <td>mind</td>\n",
       "      <td>States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>French</td>\n",
       "      <td>buy</td>\n",
       "      <td>’ll</td>\n",
       "      <td>God exists</td>\n",
       "      <td>brains</td>\n",
       "      <td>women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Mongols</td>\n",
       "      <td>lot</td>\n",
       "      <td>control</td>\n",
       "      <td>awesome people</td>\n",
       "      <td>Yale</td>\n",
       "      <td>social groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Roman</td>\n",
       "      <td>supply</td>\n",
       "      <td>machines</td>\n",
       "      <td>association with PBS</td>\n",
       "      <td>anxiety disorder</td>\n",
       "      <td>American sociologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>made World War</td>\n",
       "      <td>free market</td>\n",
       "      <td>programming languages</td>\n",
       "      <td>belief</td>\n",
       "      <td>mental</td>\n",
       "      <td>Bubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>revolution</td>\n",
       "      <td>taxes</td>\n",
       "      <td>bit</td>\n",
       "      <td>God commands</td>\n",
       "      <td>thoughts</td>\n",
       "      <td>black people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Europeans</td>\n",
       "      <td>Economists call</td>\n",
       "      <td>Turing</td>\n",
       "      <td>’ve</td>\n",
       "      <td>emotions</td>\n",
       "      <td>United</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               World History               Economics  \\\n",
       "0             Thought Bubble          Thought Bubble   \n",
       "1                 John Green                  people   \n",
       "2              World History               Economics   \n",
       "3                  World War  Crash Course Economics   \n",
       "4                      World  Jacob Clifford Adriene   \n",
       "5         Indian Ocean trade                   Crash   \n",
       "6      history teacher Raoul      Adriene Hill Jacob   \n",
       "7                Open Letter          Jacob Clifford   \n",
       "8               Roman Empire            Adriene Hill   \n",
       "9                        war                 Adriene   \n",
       "10                       n’t                   money   \n",
       "11                   History           United States   \n",
       "12               Stan Muller                economic   \n",
       "13                     Green                   price   \n",
       "14                    people              government   \n",
       "15       high school history              economists   \n",
       "16                   Thought                  prices   \n",
       "17       teacher Raoul Meyer                   Jacob   \n",
       "18       American Revolution             Theme Music   \n",
       "19    school history teacher                 economy   \n",
       "20                     Crash                Clifford   \n",
       "21                     China                     GDP   \n",
       "22                    Bubble                    make   \n",
       "23         French Revolution          watching Crash   \n",
       "24              Indian Ocean                  market   \n",
       "25                      Stan                     n’t   \n",
       "26                      week                 Thought   \n",
       "27             Latin America                  Bubble   \n",
       "28               Raoul Meyer            money supply   \n",
       "29                    Empire        economic thought   \n",
       "30  secret compartment today                    cost   \n",
       "31            Danica Johnson              make Crash   \n",
       "32                   British                   costs   \n",
       "33      Eastern Roman Empire    Thought Bubble Jacob   \n",
       "34           John Green King               countries   \n",
       "35                      John       Crash Course free   \n",
       "36                    Europe                   world   \n",
       "37                 Years War                 markets   \n",
       "38        British East India                    time   \n",
       "39         Holy Roman Empire                  called   \n",
       "40      Thought Bubble today                     pay   \n",
       "41                     great                  income   \n",
       "42            school history                  things   \n",
       "43      Western Roman Empire                 workers   \n",
       "44                    French                     buy   \n",
       "45                   Mongols                     lot   \n",
       "46                     Roman                  supply   \n",
       "47            made World War             free market   \n",
       "48                revolution                   taxes   \n",
       "49                 Europeans         Economists call   \n",
       "\n",
       "                Computer Science                         Philosophy  \\\n",
       "0                       Computer                PBS digital studios   \n",
       "1               Computer Science                                n’t   \n",
       "2                      computers                     Thought Bubble   \n",
       "3   CrashCourse Computer Science            Crash Course Philosophy   \n",
       "4                           data                                God   \n",
       "5                computer memory                       Kinney Crash   \n",
       "6                         memory                       Thought Cafe   \n",
       "7                         called                                ’re   \n",
       "8                            n’t                         Philosophy   \n",
       "9                    Carrie Anne                    digital studios   \n",
       "10              computer systems                   Flash Philosophy   \n",
       "11                       program                            thought   \n",
       "12                          time                              Crash   \n",
       "13                           ’re                        PBS digital   \n",
       "14                           CPU                Crash Course Studio   \n",
       "15             computer programs                Aquinas thought God   \n",
       "16                        number                        Squarespace   \n",
       "17                          code                      Doctor Cheryl   \n",
       "18                       machine                             people   \n",
       "19         called computer files                   Cheryl C. Kinney   \n",
       "20                        system                        Theme Music   \n",
       "21                       episode                               time   \n",
       "22              operating system                             things   \n",
       "23                      programs                              world   \n",
       "24                       numbers                     PBS Space Time   \n",
       "25                        things                              thing   \n",
       "26  instruction address register                               good   \n",
       "27                       Systems                   PBS Idea Channel   \n",
       "28           computer scientists                           n’t make   \n",
       "29                       Science                                PBS   \n",
       "30                          file                               make   \n",
       "31          CrashCourse Computer                   episode of Crash   \n",
       "32                Turing Machine                             person   \n",
       "33                          bits                               life   \n",
       "34                           ’ve                             Bubble   \n",
       "35                     computing               American philosopher   \n",
       "36                           RAM             Philosophy is produced   \n",
       "37                         today                              moral   \n",
       "38                      register  Contemporary American philosopher   \n",
       "39                   instruction                    Aquinas thought   \n",
       "40                         files                           argument   \n",
       "41                         times                            studios   \n",
       "42                   File System                             Studio   \n",
       "43                        people                          n’t exist   \n",
       "44                           ’ll                         God exists   \n",
       "45                       control                     awesome people   \n",
       "46                      machines               association with PBS   \n",
       "47         programming languages                             belief   \n",
       "48                           bit                       God commands   \n",
       "49                        Turing                                ’ve   \n",
       "\n",
       "                         Psychology               Sociology  \n",
       "0                            people    Adobe Creative Cloud  \n",
       "1                             brain          Thought Bubble  \n",
       "2                    Michael Aranda                  people  \n",
       "3                     Kathleen Yale           United States  \n",
       "4                  Blake de Pastino                  social  \n",
       "5                  Nicholas Jenkins            Thought Cafe  \n",
       "6                    Ranjit Bhagwat         Black Americans  \n",
       "7                         disorders                 society  \n",
       "8                          disorder               Americans  \n",
       "9              Personality Disorder                   Crash  \n",
       "10                         behavior                American  \n",
       "11                           things         White Americans  \n",
       "12                             time                 Thought  \n",
       "13                     Thought Cafe                     n’t  \n",
       "14                          thought             Theme Music  \n",
       "15          psychological disorders          Adobe Creative  \n",
       "16                       make Crash      Studio in Missoula  \n",
       "17  Antisocial Personality Disorder        Cheryl C. Kinney  \n",
       "18                             make          Creative Cloud  \n",
       "19                              lot           Kinney Studio  \n",
       "20                  edited by Blake               sociology  \n",
       "21                      personality  Crash Course Sociology  \n",
       "22              written by Kathleen       African Americans  \n",
       "23                              ’re            social class  \n",
       "24                              n’t        American society  \n",
       "25                            Freud  social conflict theory  \n",
       "26                            thing                     ’re  \n",
       "27                       psychology            social world  \n",
       "28               editor is Nicholas                   class  \n",
       "29             Subbable subscribers       Crash Course free  \n",
       "30                            Crash            making Crash  \n",
       "31                             kind    White Americans tend  \n",
       "32                    psychological                   world  \n",
       "33                             work          Cafe and Crash  \n",
       "34                           social                   black  \n",
       "35                           called   social stratification  \n",
       "36            American psychologist                   group  \n",
       "37                          episode             nice people  \n",
       "38                           person                  groups  \n",
       "39                   sound designer                    work  \n",
       "40                            group                  theory  \n",
       "41                            sound         class Americans  \n",
       "42                            sense                  gender  \n",
       "43                             mind                  States  \n",
       "44                           brains                   women  \n",
       "45                             Yale           social groups  \n",
       "46                 anxiety disorder    American sociologist  \n",
       "47                           mental                  Bubble  \n",
       "48                         thoughts            black people  \n",
       "49                         emotions                  United  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "subjects = ['World History', 'Economics', 'Computer Science', 'Philosophy', 'Psychology', 'Sociology']\n",
    "keywords = dict()\n",
    "for subject in subjects:\n",
    "    subject_text = subject_words.loc[subject]['Text']\n",
    "    keywords[subject] = get_keywords(''.join(map(str, subject_text)))\n",
    "\n",
    "keywords = pd.DataFrame(keywords)\n",
    "display(keywords)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "3377d83e",
    "ebf15b0b",
    "cc0WVnGVMm-z",
    "clB7GTN4uwSO"
   ],
   "name": "CA2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
